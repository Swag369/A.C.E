{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "428fd126df6c46089e864de0de956f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81365949eee94adc9e7a9deee92e8a40",
              "IPY_MODEL_b526b5f4e66e4da39a7f72b9128ff28b",
              "IPY_MODEL_ff9c8687e9b94381aa3d72f116aa629c"
            ],
            "layout": "IPY_MODEL_9e4cae579b024493add763f717d3a24c"
          }
        },
        "81365949eee94adc9e7a9deee92e8a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6728dc2cf1482493efd8d13ac35e48",
            "placeholder": "​",
            "style": "IPY_MODEL_4cfe8d888a5b4420b6c3c456563b16cc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b526b5f4e66e4da39a7f72b9128ff28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93bbde42eb494adfb7480d14ba8f77c6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b40d6676a2cc4ef2a30b8d541bb81f39",
            "value": 2
          }
        },
        "ff9c8687e9b94381aa3d72f116aa629c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d5f1a8a6d94f7591621188cddf56c4",
            "placeholder": "​",
            "style": "IPY_MODEL_a43e80de2e774e64a71d6e7304798af6",
            "value": " 2/2 [01:10&lt;00:00, 30.94s/it]"
          }
        },
        "9e4cae579b024493add763f717d3a24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6728dc2cf1482493efd8d13ac35e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cfe8d888a5b4420b6c3c456563b16cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93bbde42eb494adfb7480d14ba8f77c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40d6676a2cc4ef2a30b8d541bb81f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d5f1a8a6d94f7591621188cddf56c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43e80de2e774e64a71d6e7304798af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a34a8ebb06493e93d3950af999700e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39ceed8e554a4fd0a6efcd8294945bbd",
              "IPY_MODEL_543ba15c1279487bb7afe5b6eaebb424",
              "IPY_MODEL_508f3e2a259046048b6488071826622e"
            ],
            "layout": "IPY_MODEL_ec3d4d73f3a147d180038805912d961a"
          }
        },
        "39ceed8e554a4fd0a6efcd8294945bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad3d45ef34a411b848a88e1729ffb16",
            "placeholder": "​",
            "style": "IPY_MODEL_8997669f2b554290a471d18db2c5d015",
            "value": "Map: 100%"
          }
        },
        "543ba15c1279487bb7afe5b6eaebb424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4c8487dc824144a306ac3bded5e5d9",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b0cd701b7704889b99ec06315119695",
            "value": 200
          }
        },
        "508f3e2a259046048b6488071826622e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f34394716a54c0ebc777857afc6f7b6",
            "placeholder": "​",
            "style": "IPY_MODEL_eafb342d02ff4337bbc7b7f527d108f4",
            "value": " 200/200 [00:02&lt;00:00, 80.52 examples/s]"
          }
        },
        "ec3d4d73f3a147d180038805912d961a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad3d45ef34a411b848a88e1729ffb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8997669f2b554290a471d18db2c5d015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4c8487dc824144a306ac3bded5e5d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0cd701b7704889b99ec06315119695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f34394716a54c0ebc777857afc6f7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafb342d02ff4337bbc7b7f527d108f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbb279a184674f679b4883f5ef552ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e33c2d349e341ada2ce58dc038b3f38",
              "IPY_MODEL_9b1d891f231a4216845d4be989b44f6e",
              "IPY_MODEL_2a93c8d8aa8b44bd9dbae797e991b9d2"
            ],
            "layout": "IPY_MODEL_41aeb73d6ca442a5b520684cb77d05a1"
          }
        },
        "8e33c2d349e341ada2ce58dc038b3f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5b08d438534b65aedb3d72ee6944c3",
            "placeholder": "​",
            "style": "IPY_MODEL_790d217313a14fa89e88ff5b98c9e965",
            "value": "Truncating train dataset: 100%"
          }
        },
        "9b1d891f231a4216845d4be989b44f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ce43d3bd45b454bbacc5a03c5ed778b",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f5e2c29a6ab4567a039641773aeaed8",
            "value": 200
          }
        },
        "2a93c8d8aa8b44bd9dbae797e991b9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813e5af1708e4532804403b879ba29aa",
            "placeholder": "​",
            "style": "IPY_MODEL_65bb595d4ddc4ecfae09fdc4fc87d1f8",
            "value": " 200/200 [00:00&lt;00:00, 2903.62 examples/s]"
          }
        },
        "41aeb73d6ca442a5b520684cb77d05a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5b08d438534b65aedb3d72ee6944c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "790d217313a14fa89e88ff5b98c9e965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ce43d3bd45b454bbacc5a03c5ed778b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5e2c29a6ab4567a039641773aeaed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "813e5af1708e4532804403b879ba29aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65bb595d4ddc4ecfae09fdc4fc87d1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f468d7ba04ad413fb7cca439dced864b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcfdb49b8b7443e9b2d94638d3c2892a",
              "IPY_MODEL_e9155f85bd1a4aac88faa6c5926aef5d",
              "IPY_MODEL_7fb528fe6e2f4cbabb61981c35f7e1d1"
            ],
            "layout": "IPY_MODEL_8c0a6d7f67e245c8964d7dbacf695794"
          }
        },
        "dcfdb49b8b7443e9b2d94638d3c2892a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daeee618ce20457db4060802044ff85a",
            "placeholder": "​",
            "style": "IPY_MODEL_1acfc0cbd38b4e2e91647afe86275dcc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e9155f85bd1a4aac88faa6c5926aef5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff8e8dedd024f0ca0632e91984ac7f3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dce9b659fdc4a4fb4970894fb28e58d",
            "value": 2
          }
        },
        "7fb528fe6e2f4cbabb61981c35f7e1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cb675faf00842dfbb252705f1a2d8ab",
            "placeholder": "​",
            "style": "IPY_MODEL_ab712ad8e5b64c3684fb1ca0b116c769",
            "value": " 2/2 [01:09&lt;00:00, 30.60s/it]"
          }
        },
        "8c0a6d7f67e245c8964d7dbacf695794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daeee618ce20457db4060802044ff85a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acfc0cbd38b4e2e91647afe86275dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bff8e8dedd024f0ca0632e91984ac7f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dce9b659fdc4a4fb4970894fb28e58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cb675faf00842dfbb252705f1a2d8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab712ad8e5b64c3684fb1ca0b116c769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWNyKkOH2i7v",
        "outputId": "5b377317-f863-4124-c819-b60bbe2f3336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/f8/02/2adcaa145158bf1a8295d83591d22e4103dbfd821bcaf6f3f53151ca4ffa/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m140.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install -q -U torch transformers datasets peft bitsandbytes trl accelerate\n",
        "# !pip install -q -U langchain langchain-community langchain-huggingface langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# If you have your token stored in Colab secrets, use this:\n",
        "try:\n",
        "    token = userdata.get('HUGGINGFACE_HUB_TOKEN')\n",
        "    login(token)\n",
        "except:\n",
        "    # Otherwise manual login\n",
        "    login(\"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\")"
      ],
      "metadata": {
        "id": "iTQAG-3h2xpO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset_id = \"demoversion/cf-cpp-to-python-code-generation\"\n",
        "data_files = {\n",
        "    \"train\": \"train_openai_response_transformed.jsonl\",\n",
        "    \"validation\": \"val_openai_response_transformed.jsonl\"\n",
        "}\n",
        "\n",
        "raw_datasets = load_dataset(dataset_id, data_files=data_files)\n",
        "\n",
        "# Inspect a sample\n",
        "print(\"Sample data:\", raw_datasets[\"train\"][0])\n",
        "\n",
        "\n",
        "def format_prompt(example):\n",
        "    \"\"\"\n",
        "    Extract the C++ code (user message) and Python translation (assistant message),\n",
        "    then format them into a supervised training prompt.\n",
        "    \"\"\"\n",
        "    cpp_code = example[\"messages\"][1][\"content\"]         # C++ input\n",
        "    python_answer = example[\"messages\"][2][\"content\"]    # Python output\n",
        "\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "Translate the following C++ code to Python.\n",
        "\n",
        "### C++ Input:\n",
        "{cpp_code}\n",
        "\n",
        "### Python Output:\n",
        "{python_answer}\n",
        "\"\"\"\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "\n",
        "# Apply formatting\n",
        "train_dataset = raw_datasets[\"train\"].map(format_prompt)\n",
        "\n",
        "# Take smaller subset for Colab training\n",
        "train_dataset = train_dataset.select(range(200))\n",
        "\n",
        "print(\"\\n--- Formatted Sample ---\")\n",
        "print(train_dataset[0][\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp2e_5lF3H0y",
        "outputId": "9fbb1171-ca59-4bfa-9cf3-9b26cdd38fb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data: {'messages': [{'role': 'system', 'content': '\\nYou are an agent that generates Python code based on the provided C++ source code.\\nFirst explain the code, then generate the equivalent Python code.\\nYour code should read from standard input and write to standard output.\\nIf there is custom logic in the C++ code to read input or write output from files in local, Ignore it.\\nThis code is an implementation of a competitive programming problem, Do not make any assumptions about the input format otherwise it will fail.\\nPut the generated Python code inside a code block with triple backticks.\\nExample:\\n```python\\nimport sys\\n\\ndef solve():\\n    pass\\n\\nif __name__ == \"__main__\":\\n    solve()\\n```\\n'}, {'role': 'user', 'content': \"```\\n/**\\n *    author:  tourist\\n *    created: 23.02.2020 19:04:46       \\n**/\\n#include <bits/stdc++.h>\\n\\nusing namespace std;\\n\\nint main() {\\n  ios::sync_with_stdio(false);\\n  cin.tie(0);\\n  int n;\\n  cin >> n;\\n  vector<int> a(n);\\n  for (int i = 0; i < n; i++) {\\n    cin >> a[i];\\n  }\\n  vector<int> t(n);\\n  for (int i = 0; i < n; i++) {\\n    cin >> t[i];\\n  }\\n  a.push_back((int) 1.01e9);\\n  t.push_back(0);\\n  ++n;\\n  vector<int> order(n);\\n  iota(order.begin(), order.end(), 0);\\n  sort(order.begin(), order.end(), [&](int i, int j) {\\n    return a[i] < a[j];\\n  });\\n  unsigned long long ans = 0;\\n  int last = 0;\\n  multiset<int> s;\\n  long long sum = 0;\\n  for (int i : order) {\\n    while (a[i] > last && !s.empty()) {\\n      ++last;\\n      auto it = prev(s.end());\\n      sum -= *it;\\n      s.erase(it);\\n      ans += sum;\\n    }\\n    last = a[i];\\n    s.insert(t[i]);\\n    sum += t[i];\\n  }\\n  cout << ans << '\\\\n';\\n  return 0;\\n}\\n```\"}, {'role': 'assistant', 'content': '**Explanation:**\\n\\nThe C++ code reads two integer arrays `a` and `t`, both of length `n`. The array `a` must be interpreted as times or events, and `t` as corresponding weights or costs.\\n\\nThe algorithm works as follows:\\n1. It appends a large value (`1.01e9`) to the end of `a` and a `0` to `t` (probably as a sentinel).\\n2. It creates a list of indices and sorts them by the value of `a` so that events are processed in ascending time order.\\n3. The main logic iterates through the sorted indices. For each index:\\n   - While the \"next event/event time\" `a[i]` is greater than `last` and the multiset `s` (where weights/costs are stored) is not empty:\\n     - It increments the time `last`.\\n     - Takes the largest value from `s`, subtracts it from `sum`, removes it from `s`.\\n     - Adds the current `sum` to `ans`.\\n   - Then, after processing, it sets `last = a[i]`, inserts `t[i]` into the multiset `s`, adds `t[i]` to `sum`.\\n4. Finally, it outputs `ans`.\\n\\nThis code accumulates a sum according to a rule: at each time step, it greedily removes the largest weight and adds the remaining total weights.\\n\\n**Python Translation:**\\n\\n- We use `heapq` for a multiset, using negative values since `heapq` is a min-heap (but we need max).\\n- We use direct list operations to mimic `iota` and custom sorting.\\n- We read input from standard input and output as required.\\n\\n```python\\nimport sys\\nimport heapq\\n\\ndef solve():\\n    import sys\\n    input = sys.stdin.readline\\n\\n    n = int(sys.stdin.readline())\\n    a = list(map(int, sys.stdin.readline().split()))\\n    t = list(map(int, sys.stdin.readline().split()))\\n    a.append(int(1.01e9))\\n    t.append(0)\\n    n += 1\\n\\n    order = list(range(n))\\n    order.sort(key=lambda i: a[i])\\n\\n    ans = 0\\n    last = 0\\n    s = []\\n    sum_t = 0\\n\\n    for i in order:\\n        # While there are times between last and a[i], and the heap is not empty\\n        while a[i] > last and s:\\n            last += 1\\n            # Get and remove largest element\\n            max_t = -heapq.heappop(s)\\n            sum_t -= max_t\\n            ans += sum_t\\n        last = a[i]\\n        heapq.heappush(s, -t[i])\\n        sum_t += t[i]\\n    print(ans)\\n\\nif __name__ == \\'__main__\\':\\n    solve()\\n```\\n**Notes:**\\n- The problem expects two space-separated arrays after \\'n\\', on separate lines.\\n- The heap is used as a max-heap by pushing negative values.\\n- The code reads full lines for efficiency, which matches competitive programming setups.'}], 'source': \"/**\\n *    author:  tourist\\n *    created: 23.02.2020 19:04:46       \\n**/\\n#include <bits/stdc++.h>\\n\\nusing namespace std;\\n\\nint main() {\\n  ios::sync_with_stdio(false);\\n  cin.tie(0);\\n  int n;\\n  cin >> n;\\n  vector<int> a(n);\\n  for (int i = 0; i < n; i++) {\\n    cin >> a[i];\\n  }\\n  vector<int> t(n);\\n  for (int i = 0; i < n; i++) {\\n    cin >> t[i];\\n  }\\n  a.push_back((int) 1.01e9);\\n  t.push_back(0);\\n  ++n;\\n  vector<int> order(n);\\n  iota(order.begin(), order.end(), 0);\\n  sort(order.begin(), order.end(), [&](int i, int j) {\\n    return a[i] < a[j];\\n  });\\n  unsigned long long ans = 0;\\n  int last = 0;\\n  multiset<int> s;\\n  long long sum = 0;\\n  for (int i : order) {\\n    while (a[i] > last && !s.empty()) {\\n      ++last;\\n      auto it = prev(s.end());\\n      sum -= *it;\\n      s.erase(it);\\n      ans += sum;\\n    }\\n    last = a[i];\\n    s.insert(t[i]);\\n    sum += t[i];\\n  }\\n  cout << ans << '\\\\n';\\n  return 0;\\n}\", 'contest_id': 1310, 'index': 'A'}\n",
            "\n",
            "--- Formatted Sample ---\n",
            "### Instruction:\n",
            "Translate the following C++ code to Python.\n",
            "\n",
            "### C++ Input:\n",
            "```\n",
            "/**\n",
            " *    author:  tourist\n",
            " *    created: 23.02.2020 19:04:46       \n",
            "**/\n",
            "#include <bits/stdc++.h>\n",
            "\n",
            "using namespace std;\n",
            "\n",
            "int main() {\n",
            "  ios::sync_with_stdio(false);\n",
            "  cin.tie(0);\n",
            "  int n;\n",
            "  cin >> n;\n",
            "  vector<int> a(n);\n",
            "  for (int i = 0; i < n; i++) {\n",
            "    cin >> a[i];\n",
            "  }\n",
            "  vector<int> t(n);\n",
            "  for (int i = 0; i < n; i++) {\n",
            "    cin >> t[i];\n",
            "  }\n",
            "  a.push_back((int) 1.01e9);\n",
            "  t.push_back(0);\n",
            "  ++n;\n",
            "  vector<int> order(n);\n",
            "  iota(order.begin(), order.end(), 0);\n",
            "  sort(order.begin(), order.end(), [&](int i, int j) {\n",
            "    return a[i] < a[j];\n",
            "  });\n",
            "  unsigned long long ans = 0;\n",
            "  int last = 0;\n",
            "  multiset<int> s;\n",
            "  long long sum = 0;\n",
            "  for (int i : order) {\n",
            "    while (a[i] > last && !s.empty()) {\n",
            "      ++last;\n",
            "      auto it = prev(s.end());\n",
            "      sum -= *it;\n",
            "      s.erase(it);\n",
            "      ans += sum;\n",
            "    }\n",
            "    last = a[i];\n",
            "    s.insert(t[i]);\n",
            "    sum += t[i];\n",
            "  }\n",
            "  cout << ans << '\\n';\n",
            "  return 0;\n",
            "}\n",
            "```\n",
            "\n",
            "### Python Output:\n",
            "**Explanation:**\n",
            "\n",
            "The C++ code reads two integer arrays `a` and `t`, both of length `n`. The array `a` must be interpreted as times or events, and `t` as corresponding weights or costs.\n",
            "\n",
            "The algorithm works as follows:\n",
            "1. It appends a large value (`1.01e9`) to the end of `a` and a `0` to `t` (probably as a sentinel).\n",
            "2. It creates a list of indices and sorts them by the value of `a` so that events are processed in ascending time order.\n",
            "3. The main logic iterates through the sorted indices. For each index:\n",
            "   - While the \"next event/event time\" `a[i]` is greater than `last` and the multiset `s` (where weights/costs are stored) is not empty:\n",
            "     - It increments the time `last`.\n",
            "     - Takes the largest value from `s`, subtracts it from `sum`, removes it from `s`.\n",
            "     - Adds the current `sum` to `ans`.\n",
            "   - Then, after processing, it sets `last = a[i]`, inserts `t[i]` into the multiset `s`, adds `t[i]` to `sum`.\n",
            "4. Finally, it outputs `ans`.\n",
            "\n",
            "This code accumulates a sum according to a rule: at each time step, it greedily removes the largest weight and adds the remaining total weights.\n",
            "\n",
            "**Python Translation:**\n",
            "\n",
            "- We use `heapq` for a multiset, using negative values since `heapq` is a min-heap (but we need max).\n",
            "- We use direct list operations to mimic `iota` and custom sorting.\n",
            "- We read input from standard input and output as required.\n",
            "\n",
            "```python\n",
            "import sys\n",
            "import heapq\n",
            "\n",
            "def solve():\n",
            "    import sys\n",
            "    input = sys.stdin.readline\n",
            "\n",
            "    n = int(sys.stdin.readline())\n",
            "    a = list(map(int, sys.stdin.readline().split()))\n",
            "    t = list(map(int, sys.stdin.readline().split()))\n",
            "    a.append(int(1.01e9))\n",
            "    t.append(0)\n",
            "    n += 1\n",
            "\n",
            "    order = list(range(n))\n",
            "    order.sort(key=lambda i: a[i])\n",
            "\n",
            "    ans = 0\n",
            "    last = 0\n",
            "    s = []\n",
            "    sum_t = 0\n",
            "\n",
            "    for i in order:\n",
            "        # While there are times between last and a[i], and the heap is not empty\n",
            "        while a[i] > last and s:\n",
            "            last += 1\n",
            "            # Get and remove largest element\n",
            "            max_t = -heapq.heappop(s)\n",
            "            sum_t -= max_t\n",
            "            ans += sum_t\n",
            "        last = a[i]\n",
            "        heapq.heappush(s, -t[i])\n",
            "        sum_t += t[i]\n",
            "    print(ans)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    solve()\n",
            "```\n",
            "**Notes:**\n",
            "- The problem expects two space-separated arrays after 'n', on separate lines.\n",
            "- The heap is used as a max-heap by pushing negative values.\n",
            "- The code reads full lines for efficiency, which matches competitive programming setups.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"bigcode/starcoderbase-3b\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    use_cache=False # distinct for training\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "428fd126df6c46089e864de0de956f40",
            "81365949eee94adc9e7a9deee92e8a40",
            "b526b5f4e66e4da39a7f72b9128ff28b",
            "ff9c8687e9b94381aa3d72f116aa629c",
            "9e4cae579b024493add763f717d3a24c",
            "7d6728dc2cf1482493efd8d13ac35e48",
            "4cfe8d888a5b4420b6c3c456563b16cc",
            "93bbde42eb494adfb7480d14ba8f77c6",
            "b40d6676a2cc4ef2a30b8d541bb81f39",
            "c7d5f1a8a6d94f7591621188cddf56c4",
            "a43e80de2e774e64a71d6e7304798af6"
          ]
        },
        "id": "eJr6eDSP3LI_",
        "outputId": "709bbbd5-d28d-4c8f-cc75-f13d35744271"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "428fd126df6c46089e864de0de956f40"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"c_proj\", \"c_attn\", \"q_attn\"] # Target modules for GPTBigCode (StarCoder)\n",
        ")"
      ],
      "metadata": {
        "id": "sv_n7AuL3N8a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "def tokenize_function(example):\n",
        "    tokens = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "    )\n",
        "    return tokens\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./starcoder-finetuned\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "\n",
        "    # 🔥 Disable ALL online logging\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    formatting_func=None,\n",
        "    peft_config=peft_config,\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "new_model_name = \"starcoder-cpp2py-adapter\"\n",
        "trainer.model.save_pretrained(new_model_name)\n",
        "tokenizer.save_pretrained(new_model_name)\n",
        "\n",
        "print(\"Training complete and adapters saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238,
          "referenced_widgets": [
            "39a34a8ebb06493e93d3950af999700e",
            "39ceed8e554a4fd0a6efcd8294945bbd",
            "543ba15c1279487bb7afe5b6eaebb424",
            "508f3e2a259046048b6488071826622e",
            "ec3d4d73f3a147d180038805912d961a",
            "cad3d45ef34a411b848a88e1729ffb16",
            "8997669f2b554290a471d18db2c5d015",
            "4a4c8487dc824144a306ac3bded5e5d9",
            "2b0cd701b7704889b99ec06315119695",
            "5f34394716a54c0ebc777857afc6f7b6",
            "eafb342d02ff4337bbc7b7f527d108f4",
            "bbb279a184674f679b4883f5ef552ad7",
            "8e33c2d349e341ada2ce58dc038b3f38",
            "9b1d891f231a4216845d4be989b44f6e",
            "2a93c8d8aa8b44bd9dbae797e991b9d2",
            "41aeb73d6ca442a5b520684cb77d05a1",
            "4a5b08d438534b65aedb3d72ee6944c3",
            "790d217313a14fa89e88ff5b98c9e965",
            "9ce43d3bd45b454bbacc5a03c5ed778b",
            "8f5e2c29a6ab4567a039641773aeaed8",
            "813e5af1708e4532804403b879ba29aa",
            "65bb595d4ddc4ecfae09fdc4fc87d1f8"
          ]
        },
        "id": "IFBgcUh922qT",
        "outputId": "c829f184-d498-4773-8b71-0fa8b4e24d94"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39a34a8ebb06493e93d3950af999700e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbb279a184674f679b4883f5ef552ad7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 02:12, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.958600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.832500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete and adapters saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"Memory cleared.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzJaBu9j3SpP",
        "outputId": "d17252d0-2c23-4f84-901d-f0a9b5837ad3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# 1. Load Base Model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# 2. Load Adapters\n",
        "model = PeftModel.from_pretrained(base_model, new_model_name)\n",
        "\n",
        "# 3. Create Pipeline\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "text_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# 4. Wrap in LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_pipe)\n",
        "\n",
        "print(\"Fine-tuned model loaded into LangChain!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "f468d7ba04ad413fb7cca439dced864b",
            "dcfdb49b8b7443e9b2d94638d3c2892a",
            "e9155f85bd1a4aac88faa6c5926aef5d",
            "7fb528fe6e2f4cbabb61981c35f7e1d1",
            "8c0a6d7f67e245c8964d7dbacf695794",
            "daeee618ce20457db4060802044ff85a",
            "1acfc0cbd38b4e2e91647afe86275dcc",
            "bff8e8dedd024f0ca0632e91984ac7f3",
            "7dce9b659fdc4a4fb4970894fb28e58d",
            "9cb675faf00842dfbb252705f1a2d8ab",
            "ab712ad8e5b64c3684fb1ca0b116c769"
          ]
        },
        "id": "AstaKnVd3WxS",
        "outputId": "d34e462d-3296-4aba-ba88-69859e6fefd4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f468d7ba04ad413fb7cca439dced864b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model loaded into LangChain!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 1. Define State\n",
        "class AgentState(TypedDict):\n",
        "    cpp_code: str\n",
        "    python_code: str\n",
        "\n",
        "# 2. Define Node Function\n",
        "def convert_cpp_to_python(state: AgentState):\n",
        "    cpp_input = state[\"cpp_code\"]\n",
        "\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "Translate the following C++ code to Python.\n",
        "\n",
        "### C++ Input:\n",
        "{cpp_input}\n",
        "\n",
        "### Python Output:\n",
        "\"\"\"\n",
        "    # Invoke the fine-tuned model\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    # Clean up response (remove the input prompt if the model echoes it)\n",
        "    # StarCoder often just continues, but we ensure we grab the new text.\n",
        "    if prompt in response:\n",
        "        response = response.replace(prompt, \"\")\n",
        "\n",
        "    return {\"python_code\": response.strip()}\n",
        "\n",
        "print(\"Nodes defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdLrniCz3h9Z",
        "outputId": "7c610304-6a91-4084-9976-3bc1d5fb9371"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize Graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# 2. Add Nodes\n",
        "workflow.add_node(\"translator\", convert_cpp_to_python)\n",
        "\n",
        "# 3. Define Edges\n",
        "workflow.set_entry_point(\"translator\")\n",
        "workflow.add_edge(\"translator\", END)\n",
        "\n",
        "# 4. Compile\n",
        "app = workflow.compile()\n",
        "\n",
        "# 5. Test Data (A simple C++ Snippet)\n",
        "cpp_snippet = \"\"\"\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "int main() {\n",
        "    int n = 10;\n",
        "    if (n > 5) {\n",
        "        cout << \"Greater than 5\" << endl;\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Running LangGraph with Fine-Tuned StarCoder ---\")\n",
        "inputs = {\"cpp_code\": cpp_snippet}\n",
        "result = app.invoke(inputs)\n",
        "\n",
        "print(\"\\n### Generated Python Code ###\\n\")\n",
        "print(result[\"python_code\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9alwBk3F3j4X",
        "outputId": "2d2a277e-392a-45ad-dab8-a41fa99bce42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running LangGraph with Fine-Tuned StarCoder ---\n",
            "\n",
            "### Generated Python Code ###\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# 1️⃣ Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder2-3b\")\n",
        "\n",
        "# 2️⃣ Load base model in 8-bit to save GPU memory\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"bigcode/starcoder2-3b\",\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=None,\n",
        ")\n",
        "\n",
        "# 3️⃣ Load LoRA adapter\n",
        "adapter_dir = \"starcoder-cpp2py-adapter\"\n",
        "model = PeftModel.from_pretrained(base_model, adapter_dir)\n",
        "model.eval()\n",
        "\n",
        "# 4️⃣ Prepare C++ code input\n",
        "cpp_snippet = \"\"\"\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "int main() {\n",
        "    int n = 10;\n",
        "    if (n > 5) {\n",
        "        cout << \"Greater than 5\" << endl;\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"### Instruction:\n",
        "Translate the following C++ code to Python.\n",
        "\n",
        "### C++ Input:\n",
        "{cpp_snippet}\n",
        "\n",
        "### Python Output:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# 5️⃣ Generate Python code\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "# 6️⃣ Decode and print\n",
        "python_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"--- Generated Python Code ---\\n\")\n",
        "print(python_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS6LVNW_EY24",
        "outputId": "231a81f3-548e-4bc9-f6ff-3c61a8c15ab2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py:598: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.c_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.c_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.c_proj.lora_B.default.weight'].\n",
            "  warnings.warn(warn_message)\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generated Python Code ---\n",
            "\n",
            "### Instruction:\n",
            "Translate the following C++ code to Python.\n",
            "\n",
            "### C++ Input:\n",
            "\n",
            "#include <iostream>\n",
            "using namespace std;\n",
            "\n",
            "int main() {\n",
            "    int n = 10;\n",
            "    if (n > 5) {\n",
            "        cout << \"Greater than 5\" << endl;\n",
            "    }\n",
            "    return 0;\n",
            "}\n",
            "\n",
            "\n",
            "### Python Output:\n",
            "\n",
            "n = 10\n",
            "if n > 5:\n",
            "    print(\"Greater than 5\")\n",
            "/src/main/java/com/github/hcsp/polymorphism/Main.java\n",
            "package com.github.hcsp.polymorphism;\n",
            "\n",
            "import java.util.ArrayList;\n",
            "import java.util.List;\n",
            "\n",
            "public class Main {\n",
            "    public static void main(String[] args) {\n",
            "        List<Animal> animals = new ArrayList<>();\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "        animals.add(new Cat());\n",
            "        animals.add(new Dog());\n",
            "       \n"
          ]
        }
      ]
    }
  ]
}