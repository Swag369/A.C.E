{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4aa2932f4ad44d41ad3009ce57d4c2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_ec9a260aa2794d6395a75c22f956e447"
          }
        },
        "e378becac09c4b5ca14811d4681d273d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d04ef22f2e724d3cadee96fd72737067",
            "placeholder": "​",
            "style": "IPY_MODEL_5a77a85dc92c4b5194b477e7db722dd0",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f1115a826b6d418986b2640aadb36ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ed4563655b48473aac8301ebafd6c61c",
            "placeholder": "​",
            "style": "IPY_MODEL_745614c5e4644fd29a93071f461e9009",
            "value": ""
          }
        },
        "0eea487c479e4e759aeca014eba46a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_024aebfd751541a2adaba07d119a104f",
            "style": "IPY_MODEL_ad196ee1871f47d8bf1299f64727be19",
            "value": true
          }
        },
        "683b9a2e90544e4182f74cfa1d2d4c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ce930df124a54e62904311f5d030c3a4",
            "style": "IPY_MODEL_df68ad55d7e244b39acda49fc80ff619",
            "tooltip": ""
          }
        },
        "3126b91944fc4e52927a625f488088a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78585ddead8a4a2d9b5bc6dee7ec5799",
            "placeholder": "​",
            "style": "IPY_MODEL_f57a0475b462485e94bdde9a034d5f79",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ec9a260aa2794d6395a75c22f956e447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d04ef22f2e724d3cadee96fd72737067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a77a85dc92c4b5194b477e7db722dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed4563655b48473aac8301ebafd6c61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "745614c5e4644fd29a93071f461e9009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024aebfd751541a2adaba07d119a104f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad196ee1871f47d8bf1299f64727be19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce930df124a54e62904311f5d030c3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df68ad55d7e244b39acda49fc80ff619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "78585ddead8a4a2d9b5bc6dee7ec5799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57a0475b462485e94bdde9a034d5f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c90507c4bed74bbd9dae0983e7fe8ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7251b47ebc4745f8b4797040e1173ad3",
            "placeholder": "​",
            "style": "IPY_MODEL_fa4c8ffe19d2471fb0ffda5359a6f36b",
            "value": "Connecting..."
          }
        },
        "7251b47ebc4745f8b4797040e1173ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4c8ffe19d2471fb0ffda5359a6f36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efe9ead585fb4f0c8e8280098b2a1872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5b391949a784bf39712109778f21212",
              "IPY_MODEL_5c43665e4eeb4d31a40c488bd569e289",
              "IPY_MODEL_4bcfa90f10784bc99a490fc5a610b09c"
            ],
            "layout": "IPY_MODEL_be32b4da7dae44edaf395ee4cd9f2074"
          }
        },
        "b5b391949a784bf39712109778f21212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_991227b6c08648189b4f2c42401b7faa",
            "placeholder": "​",
            "style": "IPY_MODEL_5b06c80b2f0b46ea806bf7aeee6c072d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5c43665e4eeb4d31a40c488bd569e289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7411e8c3f1094036a522880a64a93dda",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_316e129c2b4f49deaa86f58fbc633b18",
            "value": 2
          }
        },
        "4bcfa90f10784bc99a490fc5a610b09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adff8e03e704431ea7087e7ffcc80ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_4b4e19371f814810a5549c56b208cf37",
            "value": " 2/2 [01:05&lt;00:00, 29.69s/it]"
          }
        },
        "be32b4da7dae44edaf395ee4cd9f2074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991227b6c08648189b4f2c42401b7faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b06c80b2f0b46ea806bf7aeee6c072d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7411e8c3f1094036a522880a64a93dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316e129c2b4f49deaa86f58fbc633b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adff8e03e704431ea7087e7ffcc80ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b4e19371f814810a5549c56b208cf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!apt-get update\n",
        "!apt-get install -y build-essential\n",
        "\n",
        "\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | python -\n",
        "\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "\n",
        "!pip install axolotl\n",
        "!pip install datasets transformers peft bitsandbytes\n",
        "!pip install huggingface-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NiSCNNM_1qWt",
        "outputId": "7631f328-19cf-4888-9b22-7f3bd35955ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [1 InRelease 12.7 kB/129 k\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connected to cloud.r-proj\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [2 InRelease 3,632 B/3,632 B 100%] [Connected to r2u.s\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r                                                                               \rGet:4 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                               \r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                              \rHit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rHit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\r                                                                               \r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                              \rHit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,532 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,290 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,149 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,864 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,829 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,465 kB]\n",
            "Fetched 31.1 MB in 5s (5,952 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "  File \"<stdin>\", line 105\n",
            "    This script detects what platform you're on and fetches an appropriate archive from\n",
            "                                         ^\n",
            "SyntaxError: unterminated string literal (detected at line 105)\n",
            "curl: (23) Failure writing output to destination\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting axolotl\n",
            "  Downloading axolotl-0.12.2.tar.gz (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes==0.47.0 (from axolotl)\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Collecting triton<3.4.0,>=3.0.0 (from axolotl)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting autoawq==0.2.7.post3 (from axolotl)\n",
            "  Downloading autoawq-0.2.7.post3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting liger-kernel==0.6.1 (from axolotl)\n",
            "  Downloading liger_kernel-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting packaging==23.2 (from axolotl)\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.33.0 in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.36.0)\n",
            "Collecting peft==0.17.0 (from axolotl)\n",
            "  Downloading peft-0.17.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting transformers==4.55.2 (from axolotl)\n",
            "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.22.1)\n",
            "Collecting accelerate==1.10.0 (from axolotl)\n",
            "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: datasets==4.0.0 in /usr/local/lib/python3.12/dist-packages (from axolotl) (4.0.0)\n",
            "Collecting trl==0.21.0 (from axolotl)\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting hf_xet==1.1.5 (from axolotl)\n",
            "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting kernels==0.9.0 (from axolotl)\n",
            "  Downloading kernels-0.9.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting trackio (from axolotl)\n",
            "  Downloading trackio-0.9.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting optimum==1.16.2 (from axolotl)\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.1.9)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.2.1)\n",
            "Collecting gradio==5.41.1 (from axolotl)\n",
            "  Downloading gradio-5.41.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting modal==1.0.2 (from axolotl)\n",
            "  Downloading modal-1.0.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pydantic==2.10.6 (from axolotl)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting addict (from axolotl)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from axolotl) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from axolotl) (2.32.4)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.22.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.8.1)\n",
            "Collecting colorama (from axolotl)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.60.0)\n",
            "Collecting numpy<=2.0.1,>=1.24.4 (from axolotl)\n",
            "  Downloading numpy-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.4.1 (from axolotl)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from axolotl) (1.16.3)\n",
            "Collecting scikit-learn==1.4.2 (from axolotl)\n",
            "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py==12.560.30 (from axolotl)\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting art (from axolotl)\n",
            "  Downloading art-6.5-py3-none-any.whl.metadata (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from axolotl) (2.19.0)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting s3fs>=2024.5.0 (from axolotl)\n",
            "  Downloading s3fs-2025.10.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: gcsfs>=2024.5.0 in /usr/local/lib/python3.12/dist-packages (from axolotl) (2025.3.0)\n",
            "Collecting adlfs>=2024.5.0 (from axolotl)\n",
            "  Downloading adlfs-2025.8.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ocifs==1.3.2 (from axolotl)\n",
            "  Downloading ocifs-1.3.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl)\n",
            "  Downloading zstandard-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.12/dist-packages (from axolotl) (1.8.16)\n",
            "Collecting lm_eval==0.4.7 (from axolotl)\n",
            "  Downloading lm_eval-0.4.7-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect==1.0.9 (from axolotl)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting immutabledict==4.2.0 (from axolotl)\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from axolotl)\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Collecting torchao==0.12.0 (from axolotl)\n",
            "  Downloading torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting schedulefree==1.4.1 (from axolotl)\n",
            "  Downloading schedulefree-1.4.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting axolotl-contribs-lgpl==0.0.6 (from axolotl)\n",
            "  Downloading axolotl_contribs_lgpl-0.0.6.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting axolotl-contribs-mit==0.0.5 (from axolotl)\n",
            "  Downloading axolotl_contribs_mit-0.0.5.tar.gz (21 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mistral-common==1.8.3 (from axolotl)\n",
            "  Downloading mistral_common-1.8.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting torch==2.6.0 (from axolotl)\n",
            "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting xformers==0.0.29.post3 (from axolotl)\n",
            "  Downloading xformers-0.0.29.post3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.10.0->axolotl) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.10.0->axolotl) (0.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from autoawq==0.2.7.post3->axolotl) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0->axolotl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->axolotl) (2025.3.0)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (1.0.0)\n",
            "Collecting gradio-client==1.11.0 (from gradio==5.41.1->axolotl)\n",
            "  Downloading gradio_client-1.11.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (3.11.4)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.41.1->axolotl) (0.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect==1.0.9->axolotl) (1.17.0)\n",
            "Collecting jsonlines (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from lm_eval==0.4.7->axolotl) (2.14.1)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting pytablewriter (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlitedict (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting word2number (from lm_eval==0.4.7->axolotl)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.12/dist-packages (from lm_eval==0.4.7->axolotl) (10.8.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral-common==1.8.3->axolotl) (4.25.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from mistral-common==1.8.3->axolotl) (0.12.0)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common==1.8.3->axolotl)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from modal==1.0.2->axolotl) (3.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from modal==1.0.2->axolotl) (2025.10.5)\n",
            "Collecting click~=8.1.0 (from modal==1.0.2->axolotl)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpclib==0.4.7 (from modal==1.0.2->axolotl)\n",
            "  Downloading grpclib-0.4.7.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf!=4.24.0,<7.0,>=3.19 in /usr/local/lib/python3.12/dist-packages (from modal==1.0.2->axolotl) (5.29.5)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from modal==1.0.2->axolotl) (13.9.4)\n",
            "Collecting synchronicity~=0.9.12 (from modal==1.0.2->axolotl)\n",
            "  Downloading synchronicity-0.9.16-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from modal==1.0.2->axolotl) (0.10.2)\n",
            "Collecting types-certifi (from modal==1.0.2->axolotl)\n",
            "  Downloading types_certifi-2021.10.8.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting types-toml (from modal==1.0.2->axolotl)\n",
            "  Downloading types_toml-0.10.8.20240310-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting watchfiles (from modal==1.0.2->axolotl)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting oci>=2.43.1 (from ocifs==1.3.2->axolotl)\n",
            "  Downloading oci-2.164.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from optimum==1.16.2->axolotl) (1.13.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.10.6->axolotl) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic==2.10.6->axolotl)\n",
            "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->axolotl) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->axolotl) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0->axolotl) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->axolotl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton<3.4.0,>=3.0.0 (from axolotl)\n",
            "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0->axolotl) (75.2.0)\n",
            "Collecting sympy (from optimum==1.16.2->axolotl)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.55.2->axolotl) (2024.11.6)\n",
            "Collecting tokenizers>=0.21.1 (from axolotl)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.0->gradio==5.41.1->axolotl) (15.0.1)\n",
            "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from grpclib==0.4.7->modal==1.0.2->axolotl) (4.3.0)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.12/dist-packages (from grpclib==0.4.7->modal==1.0.2->axolotl) (6.7.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->optimum==1.16.2->axolotl) (1.3.0)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from adlfs>=2024.5.0->axolotl)\n",
            "  Downloading azure_core-1.36.0-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-datalake-store<0.1,>=0.0.53 (from adlfs>=2024.5.0->axolotl)\n",
            "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting azure-identity (from adlfs>=2024.5.0->axolotl)\n",
            "  Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.17.0 (from adlfs>=2024.5.0->axolotl)\n",
            "  Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.5.0->axolotl) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.5.0->axolotl) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.5.0->axolotl) (1.2.3)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.5.0->axolotl) (2.19.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->axolotl) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->axolotl) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->axolotl) (2.5.0)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.5.0->axolotl)\n",
            "  Downloading aiobotocore-2.25.2-py3-none-any.whl.metadata (25 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs>=2024.5.0 (from axolotl)\n",
            "  Downloading s3fs-2025.9.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "  Downloading s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "  Downloading s3fs-2025.5.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->axolotl) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->axolotl) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->axolotl) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->axolotl) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->axolotl) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->axolotl) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->axolotl) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of trackio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting trackio (from axolotl)\n",
            "  Downloading trackio-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading trackio-0.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading trackio-0.8.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading trackio-0.7.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading trackio-0.6.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading trackio-0.5.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading trackio-0.5.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "INFO: pip is still looking at multiple versions of trackio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading trackio-0.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading trackio-0.4.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading trackio-0.4.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "  Downloading trackio-0.3.4-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading trackio-0.3.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading trackio-0.3.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading trackio-0.3.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading trackio-0.2.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading trackio-0.2.8-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading trackio-0.2.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->axolotl) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->axolotl) (4.5.0)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->axolotl) (2.44.0)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl)\n",
            "  Downloading aioitertools-0.13.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting botocore<1.40.71,>=1.40.46 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl)\n",
            "  Downloading botocore-1.40.70-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl) (2.9.0.post0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->modal==1.0.2->axolotl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->modal==1.0.2->axolotl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->modal==1.0.2->axolotl) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->modal==1.0.2->axolotl) (1.8.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->modal==1.0.2->axolotl) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->modal==1.0.2->axolotl) (1.22.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio==5.41.1->axolotl) (1.3.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl) (2.0.0)\n",
            "Collecting msal<2,>=1.16.0 (from azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl)\n",
            "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl) (43.0.3)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.17.0->adlfs>=2024.5.0->axolotl)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio==5.41.1->axolotl) (0.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl) (4.0.12)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio==5.41.1->axolotl) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio==5.41.1->axolotl) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral-common==1.8.3->axolotl) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral-common==1.8.3->axolotl) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral-common==1.8.3->axolotl) (0.28.0)\n",
            "Requirement already satisfied: pyOpenSSL<=25.1.0,>=17.5.0 in /usr/local/lib/python3.12/dist-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl) (24.2.1)\n",
            "Requirement already satisfied: pytz>=2016.10 in /usr/local/lib/python3.12/dist-packages (from oci>=2.43.1->ocifs==1.3.2->axolotl) (2025.2)\n",
            "Collecting circuitbreaker<3.0.0,>=1.3.1 (from oci>=2.43.1->ocifs==1.3.2->axolotl)\n",
            "  Downloading circuitbreaker-2.1.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0->axolotl) (2025.2)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common==1.8.3->axolotl)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->modal==1.0.2->axolotl) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->modal==1.0.2->axolotl) (2.19.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.7->axolotl) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl) (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->axolotl) (5.4.0)\n",
            "Collecting sigtools>=4.0.1 (from synchronicity~=0.9.12->modal==1.0.2->axolotl)\n",
            "  Downloading sigtools-4.0.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio==5.41.1->axolotl) (1.5.4)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->adlfs>=2024.5.0->axolotl)\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl) (1.7.1)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval==0.4.7->axolotl)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.7->axolotl)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.7->axolotl)\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.7->axolotl)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.7->axolotl)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7->axolotl)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl) (2.23)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl) (1.26.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3.1.0->grpclib==0.4.7->modal==1.0.2->axolotl) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3.1.0->grpclib==0.4.7->modal==1.0.2->axolotl) (4.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modal==1.0.2->axolotl) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.7->axolotl) (5.2.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs>=2024.5.0->axolotl) (2.10.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.5.0->axolotl) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl) (3.3.1)\n",
            "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoawq-0.2.7.post3-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.41.1-py3-none-any.whl (59.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading kernels-0.9.0-py3-none-any.whl (37 kB)\n",
            "Downloading liger_kernel-0.6.1-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.2/186.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.7-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.3-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modal-1.0.2-py3-none-any.whl (574 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m574.3/574.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ocifs-1.3.2-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Downloading peft-0.17.0-py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.9/503.9 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading schedulefree-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m796.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp312-cp312-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.11.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.5/324.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adlfs-2025.8.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3fs-2025.3.0-py3-none-any.whl (30 kB)\n",
            "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading art-6.5-py3-none-any.whl (610 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.4/610.4 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trackio-0.2.7-py3-none-any.whl (839 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m839.8/839.8 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.25.2-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.36.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.3/213.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.27.1-py3-none-any.whl (428 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m429.0/429.0 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oci-2.164.0-py3-none-any.whl (33.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading synchronicity-0.9.16-py3-none-any.whl (37 kB)\n",
            "Downloading azure_identity-1.25.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.3/191.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading types_certifi-2021.10.8.3-py3-none-any.whl (2.1 kB)\n",
            "Downloading types_toml-0.10.8.20240310-py3-none-any.whl (4.8 kB)\n",
            "Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.13.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.40.70-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading circuitbreaker-2.1.3-py3-none-any.whl (7.7 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sigtools-4.0.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: axolotl, axolotl-contribs-lgpl, axolotl-contribs-mit, langdetect, grpclib, rouge-score, sqlitedict, word2number\n",
            "  Building wheel for axolotl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl: filename=axolotl-0.12.2-py3-none-any.whl size=512139 sha256=3fb2a9c0d7e1d0858bec43b85b4e32933ff66e2d7c8fb3404824689218d455ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/a3/83/2b53f0fa3098a8fdb924b93cf31a304da8ac56ed13b2a2a269\n",
            "  Building wheel for axolotl-contribs-lgpl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl-contribs-lgpl: filename=axolotl_contribs_lgpl-0.0.6-py3-none-any.whl size=10897 sha256=46c41c0e8f6600678c7046565373faf2be7bbdb77d494fc0c1a3cdd4d2ac9c18\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/bc/7d/7d063242c529c81ba46ab88d97c397845d65156a860128fdf7\n",
            "  Building wheel for axolotl-contribs-mit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl-contribs-mit: filename=axolotl_contribs_mit-0.0.5-py3-none-any.whl size=23118 sha256=aca64597476eff4896eca3ef7e380aeedbe21a0e43d3e6b0cc5998f4a0731340\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c3/3c/036e7997755a5345ae6ba0b45ca727e34fdc46ea4544326e85\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=5421c43bc12a09d0eca4bfd337977efbb739571ff90cb6d22fb39817385153bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76262 sha256=f37d22d4c4ebebcceac1771d0b43c8786c96df8270771e47e6cccad09222055a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c3/8a/5d9ac03578acaa3fcb488bab3f5e6664594ca88dd8f5494ee9\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=35b4d169eb4694a41923fe89d9fc52a0d68a794117f1dfa595b68a930cfde977\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=c071d48b805a6bead6ba7e6ee45bf3c85ab71bafc31a5c52cd0e22d3c08b8aa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/6f/21/fc016aef45ffcabe27129a2252f061387cbf278d2086225a64\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=b773c962829fb690533f09b7ec7d32edea4a6789b11abc034665162383a4f28d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/79/fb/d25928e599c7e11fe4e00d32048cd74933f34a74c633d2aea6\n",
            "Successfully built axolotl axolotl-contribs-lgpl axolotl-contribs-mit langdetect grpclib rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, types-certifi, triton, torchao, sqlitedict, nvidia-ml-py, nvidia-cusparselt-cu12, circuitbreaker, antlr4-python3-runtime, addict, zstandard, wrapt, types-toml, tcolorpy, sympy, sigtools, python-dotenv, pydantic-core, pycountry, pybind11, portalocker, pathvalidate, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mbstrdecoder, langdetect, jsonlines, jmespath, isodate, immutabledict, humanfriendly, hf_xet, fire, colorama, click, art, aioitertools, watchfiles, typepy, tqdm-multiprocess, synchronicity, sacrebleu, responses, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, grpclib, coloredlogs, botocore, azure-core, tokenizers, scikit-learn, rouge-score, pydantic-extra-types, nvidia-cusolver-cu12, kernels, gradio-client, azure-storage-blob, aiobotocore, transformers, torch, s3fs, oci, msal, modal, gradio, DataProperty, xformers, trackio, tabledata, schedulefree, ocifs, msal-extensions, mistral-common, liger-kernel, evaluate, bitsandbytes, azure-datalake-store, axolotl-contribs-mit, axolotl-contribs-lgpl, accelerate, trl, pytablewriter, peft, optimum, azure-identity, autoawq, lm_eval, adlfs, axolotl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: nvidia-ml-py\n",
            "    Found existing installation: nvidia-ml-py 13.580.82\n",
            "    Uninstalling nvidia-ml-py-13.580.82:\n",
            "      Successfully uninstalled nvidia-ml-py-13.580.82\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: antlr4-python3-runtime\n",
            "    Found existing installation: antlr4-python3-runtime 4.9.3\n",
            "    Uninstalling antlr4-python3-runtime-4.9.3:\n",
            "      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.25.0\n",
            "    Uninstalling zstandard-0.25.0:\n",
            "      Successfully uninstalled zstandard-0.25.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: immutabledict\n",
            "    Found existing installation: immutabledict 4.2.2\n",
            "    Uninstalling immutabledict-4.2.2:\n",
            "      Successfully uninstalled immutabledict-4.2.2\n",
            "  Attempting uninstall: hf_xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.10\n",
            "    Uninstalling pydantic-2.11.10:\n",
            "      Successfully uninstalled pydantic-2.11.10\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: grpclib\n",
            "    Found existing installation: grpclib 0.4.8\n",
            "    Uninstalling grpclib-0.4.8:\n",
            "      Successfully uninstalled grpclib-0.4.8\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.13.3\n",
            "    Uninstalling gradio_client-1.13.3:\n",
            "      Successfully uninstalled gradio_client-1.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.49.1\n",
            "    Uninstalling gradio-5.49.1:\n",
            "      Successfully uninstalled gradio-5.49.1\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.11.0\n",
            "    Uninstalling accelerate-1.11.0:\n",
            "      Successfully uninstalled accelerate-1.11.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.1\n",
            "    Uninstalling peft-0.17.1:\n",
            "      Successfully uninstalled peft-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2025.10.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "langsmith 0.4.42 requires zstandard>=0.23.0, but you have zstandard 0.22.0 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\n",
            "google-cloud-bigquery 3.38.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "omegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.13.2 which is incompatible.\n",
            "db-dtypes 1.4.4 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "mcp 1.21.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.10.6 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.1.0 accelerate-1.10.0 addict-2.4.0 adlfs-2025.8.0 aiobotocore-2.25.2 aioitertools-0.13.0 antlr4-python3-runtime-4.13.2 art-6.5 autoawq-0.2.7.post3 axolotl-0.12.2 axolotl-contribs-lgpl-0.0.6 axolotl-contribs-mit-0.0.5 azure-core-1.36.0 azure-datalake-store-0.0.53 azure-identity-1.25.1 azure-storage-blob-12.27.1 bitsandbytes-0.47.0 botocore-1.40.70 circuitbreaker-2.1.3 click-8.1.8 colorama-0.4.6 coloredlogs-15.0.1 evaluate-0.4.1 fire-0.7.1 gradio-5.41.1 gradio-client-1.11.0 grpclib-0.4.7 hf_xet-1.1.5 humanfriendly-10.0 immutabledict-4.2.0 isodate-0.7.2 jmespath-1.0.1 jsonlines-4.0.0 kernels-0.9.0 langdetect-1.0.9 liger-kernel-0.6.1 lm_eval-0.4.7 mbstrdecoder-1.1.4 mistral-common-1.8.3 modal-1.0.2 msal-1.34.0 msal-extensions-1.3.1 numpy-2.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-ml-py-12.560.30 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 oci-2.164.0 ocifs-1.3.2 optimum-1.16.2 packaging-23.2 pathvalidate-3.3.1 peft-0.17.0 portalocker-3.2.0 pybind11-3.0.1 pycountry-24.6.1 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-extra-types-2.10.6 pytablewriter-1.2.1 python-dotenv-1.0.1 responses-0.18.0 rouge-score-0.1.2 s3fs-2025.3.0 sacrebleu-2.5.1 schedulefree-1.4.1 scikit-learn-1.4.2 sigtools-4.0.1 sqlitedict-2.1.0 sympy-1.13.1 synchronicity-0.9.16 tabledata-1.3.4 tcolorpy-0.1.7 tokenizers-0.21.4 torch-2.6.0 torchao-0.12.0 tqdm-multiprocess-0.0.11 trackio-0.2.7 transformers-4.55.2 triton-3.2.0 trl-0.21.0 typepy-1.3.4 types-certifi-2021.10.8.3 types-toml-0.10.8.20240310 watchfiles-1.1.1 word2number-1.1 wrapt-1.17.3 xformers-0.0.29.post3 zstandard-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "256e1208b7374c6683052f0299b45760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.6.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.10.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_drv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-43926903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Install axolotl and dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install axolotl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install datasets transformers peft bitsandbytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install huggingface-hub'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             self._str = self._format_parsed_parts(self.drive, self.root,\n\u001b[0m\u001b[1;32m    444\u001b[0m                                                   self._tail) or '.'\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_load_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4aa2932f4ad44d41ad3009ce57d4c2b5",
            "e378becac09c4b5ca14811d4681d273d",
            "f1115a826b6d418986b2640aadb36ca7",
            "0eea487c479e4e759aeca014eba46a63",
            "683b9a2e90544e4182f74cfa1d2d4c9c",
            "3126b91944fc4e52927a625f488088a2",
            "ec9a260aa2794d6395a75c22f956e447",
            "d04ef22f2e724d3cadee96fd72737067",
            "5a77a85dc92c4b5194b477e7db722dd0",
            "ed4563655b48473aac8301ebafd6c61c",
            "745614c5e4644fd29a93071f461e9009",
            "024aebfd751541a2adaba07d119a104f",
            "ad196ee1871f47d8bf1299f64727be19",
            "ce930df124a54e62904311f5d030c3a4",
            "df68ad55d7e244b39acda49fc80ff619",
            "78585ddead8a4a2d9b5bc6dee7ec5799",
            "f57a0475b462485e94bdde9a034d5f79",
            "c90507c4bed74bbd9dae0983e7fe8ec7",
            "7251b47ebc4745f8b4797040e1173ad3",
            "fa4c8ffe19d2471fb0ffda5359a6f36b"
          ]
        },
        "id": "DEUBJrw91u8c",
        "outputId": "dd0aeef0-17dd-4315-c9f0-f938dae1024c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aa2932f4ad44d41ad3009ce57d4c2b5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "!mkdir -p data\n",
        "\n",
        "!wget https://huggingface.co/datasets/demoversion/cf-cpp-to-python-code-generation/resolve/main/train_openai_response_transformed.jsonl -O ./data/train_openai_response_transformed.jsonl\n",
        "\n",
        "!wget https://huggingface.co/datasets/demoversion/cf-cpp-to-python-code-generation/resolve/main/val_openai_response_transformed.jsonl -O ./data/val_openai_response_transformed.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYObQVbb2Lno",
        "outputId": "9f26c6ff-78ae-48ae-a5f8-ca932da8279f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-19 02:08:17--  https://huggingface.co/datasets/demoversion/cf-cpp-to-python-code-generation/resolve/main/train_openai_response_transformed.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.103, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /api/resolve-cache/datasets/demoversion/cf-cpp-to-python-code-generation/23ce116110db54eee84ddd8180ce1514812844c8/train_openai_response_transformed.jsonl?%2Fdatasets%2Fdemoversion%2Fcf-cpp-to-python-code-generation%2Fresolve%2Fmain%2Ftrain_openai_response_transformed.jsonl=&etag=%22387cf31722231549f86fe171e13dfffcc13e8e0d%22 [following]\n",
            "--2025-11-19 02:08:17--  https://huggingface.co/api/resolve-cache/datasets/demoversion/cf-cpp-to-python-code-generation/23ce116110db54eee84ddd8180ce1514812844c8/train_openai_response_transformed.jsonl?%2Fdatasets%2Fdemoversion%2Fcf-cpp-to-python-code-generation%2Fresolve%2Fmain%2Ftrain_openai_response_transformed.jsonl=&etag=%22387cf31722231549f86fe171e13dfffcc13e8e0d%22\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9233632 (8.8M) [text/plain]\n",
            "Saving to: ‘./data/train_openai_response_transformed.jsonl’\n",
            "\n",
            "./data/train_openai 100%[===================>]   8.81M  57.0MB/s    in 0.2s    \n",
            "\n",
            "2025-11-19 02:08:18 (57.0 MB/s) - ‘./data/train_openai_response_transformed.jsonl’ saved [9233632/9233632]\n",
            "\n",
            "--2025-11-19 02:08:18--  https://huggingface.co/datasets/demoversion/cf-cpp-to-python-code-generation/resolve/main/val_openai_response_transformed.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /api/resolve-cache/datasets/demoversion/cf-cpp-to-python-code-generation/23ce116110db54eee84ddd8180ce1514812844c8/val_openai_response_transformed.jsonl?%2Fdatasets%2Fdemoversion%2Fcf-cpp-to-python-code-generation%2Fresolve%2Fmain%2Fval_openai_response_transformed.jsonl=&etag=%228db2f791e1e084533e15b89a009844f57cba9e93%22 [following]\n",
            "--2025-11-19 02:08:18--  https://huggingface.co/api/resolve-cache/datasets/demoversion/cf-cpp-to-python-code-generation/23ce116110db54eee84ddd8180ce1514812844c8/val_openai_response_transformed.jsonl?%2Fdatasets%2Fdemoversion%2Fcf-cpp-to-python-code-generation%2Fresolve%2Fmain%2Fval_openai_response_transformed.jsonl=&etag=%228db2f791e1e084533e15b89a009844f57cba9e93%22\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1935405 (1.8M) [text/plain]\n",
            "Saving to: ‘./data/val_openai_response_transformed.jsonl’\n",
            "\n",
            "./data/val_openai_r 100%[===================>]   1.85M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-11-19 02:08:18 (20.6 MB/s) - ‘./data/val_openai_response_transformed.jsonl’ saved [1935405/1935405]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "base_model: meta-llama/Llama-3.2-3B-Instruct\n",
        "model_type: llama\n",
        "tokenizer_type: LlamaTokenizerFast\n",
        "tokenizer_config: meta-llama/Llama-3.2-3B-Instruct\n",
        "\n",
        "datasets:\n",
        "  - path: ./data/train_openai_response_transformed.jsonl\n",
        "    type: chat_template\n",
        "\n",
        "val_set_size: 0.1\n",
        "val_file: ./data/val_openai_response_transformed.jsonl\n",
        "\n",
        "output_dir: ./outputs\n",
        "num_epochs: 3\n",
        "micro_batch_size: 2\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 3e-4\n",
        "warmup_steps: 100\n",
        "logging_steps: 10\n",
        "save_steps: 100\n",
        "eval_steps: 100\n",
        "max_seq_length: 1024\n",
        "seed: 42\n",
        "\n",
        "load_in_8bit: true\n",
        "fp16: true\n",
        "bf16: false\n",
        "gradient_checkpointing: true\n",
        "optimizer: adamw_torch_fused\n",
        "\n",
        "adapter: lora\n",
        "lora_r: 8\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_modules:\n",
        "  - q_proj\n",
        "  - k_proj\n",
        "  - v_proj\n",
        "  - o_proj\n",
        "\n",
        "\n",
        "save_safetensors: true\n",
        "type_of_model: llama\n",
        "strict: false\n",
        "shuffle_merged_datasets: true\n",
        "train_on_inputs: false\n",
        "torch_dtype: torch.float16\n",
        "world_size: 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A5zu5Qg2Nmb",
        "outputId": "a06f3c8a-e24e-4ccf-c2f3-c476b77f5679"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio transformers peft\n",
        "\n",
        "!pip install torch==2.1.2 torchvision==0.16.1 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "!pip install transformers==4.37.2 peft==0.10.0 accelerate==0.26.0 bitsandbytes==0.42.0\n",
        "\n",
        "!pip install axolotl\n"
      ],
      "metadata": {
        "id": "XvU8qC2o4KvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p config\n",
        "!mv config.yaml config/llama-3.2-3b-lora.yml"
      ],
      "metadata": {
        "id": "yRK85naj6eXy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && python -m axolotl.cli.preprocess config/llama-3.2-3b-lora.yml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-6cMPvk2SmN",
        "outputId": "a95b50f3-c1c6-40ee-88dd-6f654ae31bd0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-19 02:35:59.771018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763519759.805493   11269 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763519759.816344   11269 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763519759.841399   11269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763519759.841445   11269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763519759.841453   11269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763519759.841459   11269 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-19 02:35:59.848548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-11-19 02:36:11,022] [INFO] [axolotl.utils.schemas.config.check_bf16:1003] [PID:11269] [RANK:0] bf16 support detected, but not enabled for this configuration.\u001b[39m\n",
            "[2025-11-19 02:36:11,193] [INFO] [axolotl.cli.config.load_cfg:245] [PID:11269] [RANK:0] config:\n",
            "{\n",
            "  \"activation_offloading\": false,\n",
            "  \"adapter\": \"lora\",\n",
            "  \"axolotl_config_path\": \"config/llama-3.2-3b-lora.yml\",\n",
            "  \"base_model\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
            "  \"base_model_config\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
            "  \"batch_size\": 8,\n",
            "  \"bf16\": false,\n",
            "  \"capabilities\": {\n",
            "    \"bf16\": true,\n",
            "    \"compute_capability\": \"sm_75\",\n",
            "    \"fp8\": false,\n",
            "    \"n_gpu\": 1,\n",
            "    \"n_node\": 1\n",
            "  },\n",
            "  \"context_parallel_size\": 1,\n",
            "  \"dataloader_num_workers\": 1,\n",
            "  \"dataloader_pin_memory\": true,\n",
            "  \"dataloader_prefetch_factor\": 256,\n",
            "  \"dataset_processes\": 2,\n",
            "  \"datasets\": [\n",
            "    {\n",
            "      \"chat_template\": \"tokenizer_default\",\n",
            "      \"message_property_mappings\": {\n",
            "        \"content\": \"content\",\n",
            "        \"role\": \"role\"\n",
            "      },\n",
            "      \"path\": \"./data/train_openai_response_transformed.jsonl\",\n",
            "      \"trust_remote_code\": false,\n",
            "      \"type\": \"chat_template\"\n",
            "    }\n",
            "  ],\n",
            "  \"ddp\": false,\n",
            "  \"device\": \"cuda:0\",\n",
            "  \"device_map\": \"auto\",\n",
            "  \"dion_rank_fraction\": 1.0,\n",
            "  \"dion_rank_multiple_of\": 1,\n",
            "  \"env_capabilities\": {\n",
            "    \"torch_version\": \"2.6.0\"\n",
            "  },\n",
            "  \"eval_batch_size\": 2,\n",
            "  \"eval_causal_lm_metrics\": [\n",
            "    \"sacrebleu\",\n",
            "    \"comet\",\n",
            "    \"ter\",\n",
            "    \"chrf\"\n",
            "  ],\n",
            "  \"eval_max_new_tokens\": 128,\n",
            "  \"eval_steps\": 100,\n",
            "  \"eval_table_size\": 0,\n",
            "  \"fp16\": true,\n",
            "  \"gradient_accumulation_steps\": 4,\n",
            "  \"gradient_checkpointing\": true,\n",
            "  \"gradient_checkpointing_kwargs\": {\n",
            "    \"use_reentrant\": true\n",
            "  },\n",
            "  \"is_falcon_derived_model\": false,\n",
            "  \"is_llama_derived_model\": true,\n",
            "  \"is_mistral_derived_model\": false,\n",
            "  \"learning_rate\": 0.0003,\n",
            "  \"lisa_layers_attribute\": \"model.layers\",\n",
            "  \"load_best_model_at_end\": false,\n",
            "  \"load_in_4bit\": false,\n",
            "  \"load_in_8bit\": true,\n",
            "  \"local_rank\": 0,\n",
            "  \"logging_steps\": 10,\n",
            "  \"lora_alpha\": 16,\n",
            "  \"lora_dropout\": 0.05,\n",
            "  \"lora_r\": 8,\n",
            "  \"lora_target_modules\": [\n",
            "    \"q_proj\",\n",
            "    \"k_proj\",\n",
            "    \"v_proj\",\n",
            "    \"o_proj\"\n",
            "  ],\n",
            "  \"loraplus_lr_embedding\": 1e-06,\n",
            "  \"lr_scheduler\": \"cosine\",\n",
            "  \"max_prompt_len\": 512,\n",
            "  \"mean_resizing_embeddings\": false,\n",
            "  \"micro_batch_size\": 2,\n",
            "  \"model_config_type\": \"llama\",\n",
            "  \"num_epochs\": 3.0,\n",
            "  \"optimizer\": \"adamw_torch_fused\",\n",
            "  \"output_dir\": \"./outputs\",\n",
            "  \"pretrain_multipack_attn\": true,\n",
            "  \"pretrain_multipack_buffer_size\": 10000,\n",
            "  \"profiler_steps_start\": 0,\n",
            "  \"qlora_sharded_model_loading\": false,\n",
            "  \"ray_num_workers\": 1,\n",
            "  \"resources_per_worker\": {\n",
            "    \"GPU\": 1\n",
            "  },\n",
            "  \"sample_packing_bin_size\": 200,\n",
            "  \"sample_packing_group_size\": 100000,\n",
            "  \"save_only_model\": false,\n",
            "  \"save_safetensors\": true,\n",
            "  \"save_steps\": 100,\n",
            "  \"seed\": 42,\n",
            "  \"sequence_len\": 512,\n",
            "  \"shuffle_before_merging_datasets\": false,\n",
            "  \"shuffle_merged_datasets\": true,\n",
            "  \"skip_prepare_dataset\": false,\n",
            "  \"strict\": false,\n",
            "  \"tensor_parallel_size\": 1,\n",
            "  \"tiled_mlp_use_original_mlp\": true,\n",
            "  \"tokenizer_config\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
            "  \"tokenizer_type\": \"LlamaTokenizerFast\",\n",
            "  \"torch_dtype\": \"torch.float16\",\n",
            "  \"train_on_inputs\": false,\n",
            "  \"trl\": {\n",
            "    \"log_completions\": false,\n",
            "    \"mask_truncated_completions\": false,\n",
            "    \"ref_model_mixup_alpha\": 0.9,\n",
            "    \"ref_model_sync_steps\": 64,\n",
            "    \"scale_rewards\": true,\n",
            "    \"sync_ref_model\": false,\n",
            "    \"use_vllm\": false,\n",
            "    \"vllm_server_host\": \"0.0.0.0\",\n",
            "    \"vllm_server_port\": 8000\n",
            "  },\n",
            "  \"type_of_model\": \"llama\",\n",
            "  \"use_ray\": false,\n",
            "  \"val_set_size\": 0.1,\n",
            "  \"vllm\": {\n",
            "    \"device\": \"auto\",\n",
            "    \"dtype\": \"auto\",\n",
            "    \"gpu_memory_utilization\": 0.9,\n",
            "    \"host\": \"0.0.0.0\",\n",
            "    \"port\": 8000\n",
            "  },\n",
            "  \"warmup_steps\": 100,\n",
            "  \"weight_decay\": 0.0,\n",
            "  \"world_size\": 1\n",
            "}\u001b[39m\n",
            "[2025-11-19 02:36:11,298] [WARNING] [__main__.do_preprocess:52] [PID:11269] \u001b[31mpreprocess CLI called without dataset_prepared_path set, using default path: last_run_prepared\u001b[39m\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
            "The class this function is called from is 'LlamaTokenizerFast'.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "[2025-11-19 02:36:12,083] [INFO] [axolotl.loaders.tokenizer.load_tokenizer:300] [PID:11269] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-11-19 02:36:12,084] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:478] [PID:11269] [RANK:0] Unable to find prepared dataset in last_run_prepared/0d8b032105993cd50c291ef141081e49\u001b[39m\n",
            "[2025-11-19 02:36:12,085] [INFO] [axolotl.utils.data.sft._load_raw_datasets:314] [PID:11269] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "[2025-11-19 02:36:12,407] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:11269] [RANK:0] Loading dataset: ./data/train_openai_response_transformed.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-11-19 02:36:12,413] [INFO] [axolotl.prompt_strategies.chat_template.__call__:957] [PID:11269] [RANK:0] Using chat template:\n",
            "---\n",
            "{{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- if strftime_now is defined %}\n",
            "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
            "    {%- else %}\n",
            "        {%- set date_string = \"26 Jul 2024\" %}\n",
            "    {%- endif %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "        {{- '\"parameters\": ' }}\n",
            "        {{- tool_call.arguments | tojson }}\n",
            "        {{- \"}\" }}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 1400/1400 [00:15<00:00, 88.83 examples/s] \n",
            "[2025-11-19 02:36:28,402] [INFO] [axolotl.utils.data.utils.handle_long_seq_in_dataset:209] [PID:11269] [RANK:0] min_input_len: 328\u001b[39m\n",
            "[2025-11-19 02:36:28,402] [INFO] [axolotl.utils.data.utils.handle_long_seq_in_dataset:211] [PID:11269] [RANK:0] max_input_len: 10300\u001b[39m\n",
            "Dropping Long Sequences (>512) (num_proc=2): 100% 1400/1400 [00:01<00:00, 1216.90 examples/s]\n",
            "\u001b[33m[2025-11-19 02:36:29,561] [WARNING] [axolotl.utils.data.utils.handle_long_seq_in_dataset:251] [PID:11269] [RANK:0] Dropped 1346 samples from dataset\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 54/54 [00:00<00:00, 8860.51 examples/s]\n",
            "[2025-11-19 02:36:29,573] [INFO] [axolotl.common.datasets.load_datasets:74] [PID:11269] [RANK:0] check_dataset_labels...\u001b[39m\n",
            "[2025-11-19 02:36:29,579] [INFO] [axolotl.utils.tokenization.check_example_labels:44] [PID:11269] [RANK:0] \u001b[31m<|begin_of_text|>\u001b[0m\u001b[97m(-100, 128000)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31msystem\u001b[0m\u001b[97m(-100, 9125)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mCut\u001b[0m\u001b[97m(-100, 38766)\u001b[0m \u001b[31mting\u001b[0m\u001b[97m(-100, 1303)\u001b[0m \u001b[31m Knowledge\u001b[0m\u001b[97m(-100, 33025)\u001b[0m \u001b[31m Date\u001b[0m\u001b[97m(-100, 2696)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m December\u001b[0m\u001b[97m(-100, 6790)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m202\u001b[0m\u001b[97m(-100, 2366)\u001b[0m \u001b[31m3\u001b[0m\u001b[97m(-100, 18)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mToday\u001b[0m\u001b[97m(-100, 15724)\u001b[0m \u001b[31m Date\u001b[0m\u001b[97m(-100, 2696)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m19\u001b[0m\u001b[97m(-100, 777)\u001b[0m \u001b[31m Nov\u001b[0m\u001b[97m(-100, 4723)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m202\u001b[0m\u001b[97m(-100, 2366)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m agent\u001b[0m\u001b[97m(-100, 8479)\u001b[0m \u001b[31m that\u001b[0m\u001b[97m(-100, 430)\u001b[0m \u001b[31m generates\u001b[0m\u001b[97m(-100, 27983)\u001b[0m \u001b[31m Python\u001b[0m\u001b[97m(-100, 13325)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m based\u001b[0m\u001b[97m(-100, 3196)\u001b[0m \u001b[31m on\u001b[0m\u001b[97m(-100, 389)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m provided\u001b[0m\u001b[97m(-100, 3984)\u001b[0m \u001b[31m C\u001b[0m\u001b[97m(-100, 356)\u001b[0m \u001b[31m++\u001b[0m\u001b[97m(-100, 1044)\u001b[0m \u001b[31m source\u001b[0m\u001b[97m(-100, 2592)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mFirst\u001b[0m\u001b[97m(-100, 5451)\u001b[0m \u001b[31m explain\u001b[0m\u001b[97m(-100, 10552)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m then\u001b[0m\u001b[97m(-100, 1243)\u001b[0m \u001b[31m generate\u001b[0m\u001b[97m(-100, 7068)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m equivalent\u001b[0m\u001b[97m(-100, 13890)\u001b[0m \u001b[31m Python\u001b[0m\u001b[97m(-100, 13325)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mYour\u001b[0m\u001b[97m(-100, 7927)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m should\u001b[0m\u001b[97m(-100, 1288)\u001b[0m \u001b[31m read\u001b[0m\u001b[97m(-100, 1373)\u001b[0m \u001b[31m from\u001b[0m\u001b[97m(-100, 505)\u001b[0m \u001b[31m standard\u001b[0m\u001b[97m(-100, 5410)\u001b[0m \u001b[31m input\u001b[0m\u001b[97m(-100, 1988)\u001b[0m \u001b[31m and\u001b[0m\u001b[97m(-100, 323)\u001b[0m \u001b[31m write\u001b[0m\u001b[97m(-100, 3350)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m standard\u001b[0m\u001b[97m(-100, 5410)\u001b[0m \u001b[31m output\u001b[0m\u001b[97m(-100, 2612)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mIf\u001b[0m\u001b[97m(-100, 2746)\u001b[0m \u001b[31m there\u001b[0m\u001b[97m(-100, 1070)\u001b[0m \u001b[31m is\u001b[0m\u001b[97m(-100, 374)\u001b[0m \u001b[31m custom\u001b[0m\u001b[97m(-100, 2587)\u001b[0m \u001b[31m logic\u001b[0m\u001b[97m(-100, 12496)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m C\u001b[0m\u001b[97m(-100, 356)\u001b[0m \u001b[31m++\u001b[0m\u001b[97m(-100, 1044)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m read\u001b[0m\u001b[97m(-100, 1373)\u001b[0m \u001b[31m input\u001b[0m\u001b[97m(-100, 1988)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m write\u001b[0m\u001b[97m(-100, 3350)\u001b[0m \u001b[31m output\u001b[0m\u001b[97m(-100, 2612)\u001b[0m \u001b[31m from\u001b[0m\u001b[97m(-100, 505)\u001b[0m \u001b[31m files\u001b[0m\u001b[97m(-100, 3626)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m local\u001b[0m\u001b[97m(-100, 2254)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m Ignore\u001b[0m\u001b[97m(-100, 40071)\u001b[0m \u001b[31m it\u001b[0m\u001b[97m(-100, 433)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mThis\u001b[0m\u001b[97m(-100, 2028)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m is\u001b[0m\u001b[97m(-100, 374)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m implementation\u001b[0m\u001b[97m(-100, 8292)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m competitive\u001b[0m\u001b[97m(-100, 15022)\u001b[0m \u001b[31m programming\u001b[0m\u001b[97m(-100, 15840)\u001b[0m \u001b[31m problem\u001b[0m\u001b[97m(-100, 3575)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m Do\u001b[0m\u001b[97m(-100, 3234)\u001b[0m \u001b[31m not\u001b[0m\u001b[97m(-100, 539)\u001b[0m \u001b[31m make\u001b[0m\u001b[97m(-100, 1304)\u001b[0m \u001b[31m any\u001b[0m\u001b[97m(-100, 904)\u001b[0m \u001b[31m assumptions\u001b[0m\u001b[97m(-100, 32946)\u001b[0m \u001b[31m about\u001b[0m\u001b[97m(-100, 922)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m input\u001b[0m\u001b[97m(-100, 1988)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m otherwise\u001b[0m\u001b[97m(-100, 6062)\u001b[0m \u001b[31m it\u001b[0m\u001b[97m(-100, 433)\u001b[0m \u001b[31m will\u001b[0m\u001b[97m(-100, 690)\u001b[0m \u001b[31m fail\u001b[0m\u001b[97m(-100, 3775)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mPut\u001b[0m\u001b[97m(-100, 19648)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m generated\u001b[0m\u001b[97m(-100, 8066)\u001b[0m \u001b[31m Python\u001b[0m\u001b[97m(-100, 13325)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m inside\u001b[0m\u001b[97m(-100, 4871)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m block\u001b[0m\u001b[97m(-100, 2565)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m triple\u001b[0m\u001b[97m(-100, 24657)\u001b[0m \u001b[31m back\u001b[0m\u001b[97m(-100, 1203)\u001b[0m \u001b[31mticks\u001b[0m\u001b[97m(-100, 36178)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mExample\u001b[0m\u001b[97m(-100, 13617)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m```\u001b[0m\u001b[97m(-100, 74694)\u001b[0m \u001b[31mpython\u001b[0m\u001b[97m(-100, 12958)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mimport\u001b[0m\u001b[97m(-100, 475)\u001b[0m \u001b[31m sys\u001b[0m\u001b[97m(-100, 5826)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mdef\u001b[0m\u001b[97m(-100, 755)\u001b[0m \u001b[31m solve\u001b[0m\u001b[97m(-100, 11886)\u001b[0m \u001b[31m():\n",
            "\u001b[0m\u001b[97m(-100, 4019)\u001b[0m \u001b[31m   \u001b[0m\u001b[97m(-100, 262)\u001b[0m \u001b[31m pass\u001b[0m\u001b[97m(-100, 1522)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mif\u001b[0m\u001b[97m(-100, 333)\u001b[0m \u001b[31m __\u001b[0m\u001b[97m(-100, 1328)\u001b[0m \u001b[31mname\u001b[0m\u001b[97m(-100, 609)\u001b[0m \u001b[31m__\u001b[0m\u001b[97m(-100, 565)\u001b[0m \u001b[31m ==\u001b[0m\u001b[97m(-100, 624)\u001b[0m \u001b[31m \"__\u001b[0m\u001b[97m(-100, 13568)\u001b[0m \u001b[31mmain\u001b[0m\u001b[97m(-100, 3902)\u001b[0m \u001b[31m__\":\n",
            "\u001b[0m\u001b[97m(-100, 21762)\u001b[0m \u001b[31m   \u001b[0m\u001b[97m(-100, 262)\u001b[0m \u001b[31m solve\u001b[0m\u001b[97m(-100, 11886)\u001b[0m \u001b[31m()\n",
            "\u001b[0m\u001b[97m(-100, 746)\u001b[0m \u001b[31m```\u001b[0m\u001b[97m(-100, 74694)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\u001b[0m\u001b[97m(-100, 4077)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<iostream\u001b[0m\u001b[97m(-100, 37531)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<string\u001b[0m\u001b[97m(-100, 5053)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<\u001b[0m\u001b[97m(-100, 27)\u001b[0m \u001b[31msstream\u001b[0m\u001b[97m(-100, 39466)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<\u001b[0m\u001b[97m(-100, 27)\u001b[0m \u001b[31mset\u001b[0m\u001b[97m(-100, 751)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<vector\u001b[0m\u001b[97m(-100, 25266)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<\u001b[0m\u001b[97m(-100, 27)\u001b[0m \u001b[31mbitset\u001b[0m\u001b[97m(-100, 78715)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<\u001b[0m\u001b[97m(-100, 27)\u001b[0m \u001b[31mcmath\u001b[0m\u001b[97m(-100, 34825)\u001b[0m \u001b[31m>\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1363)\u001b[0m \u001b[31m#include\u001b[0m\u001b[97m(-100, 1085)\u001b[0m \u001b[31m<algorithm\u001b[0m\u001b[97m(-100, 89852)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 5244)\u001b[0m \u001b[31musing\u001b[0m\u001b[97m(-100, 985)\u001b[0m \u001b[31m namespace\u001b[0m\u001b[97m(-100, 4573)\u001b[0m \u001b[31m std\u001b[0m\u001b[97m(-100, 1487)\u001b[0m \u001b[31m;\n",
            "\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 22896)\u001b[0m \u001b[31mint\u001b[0m\u001b[97m(-100, 396)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m2\u001b[0m\u001b[97m(-100, 17)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m3\u001b[0m\u001b[97m(-100, 18)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m4\u001b[0m\u001b[97m(-100, 19)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m;\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 401)\u001b[0m \u001b[31mint\u001b[0m\u001b[97m(-100, 396)\u001b[0m \u001b[31m main\u001b[0m\u001b[97m(-100, 1925)\u001b[0m \u001b[31m()\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 2892)\u001b[0m \u001b[31m{\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 4352)\u001b[0m \u001b[31m\tcin\u001b[0m\u001b[97m(-100, 19382)\u001b[0m \u001b[31m >>\u001b[0m\u001b[97m(-100, 3662)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m >>\u001b[0m\u001b[97m(-100, 3662)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m2\u001b[0m\u001b[97m(-100, 17)\u001b[0m \u001b[31m >>\u001b[0m\u001b[97m(-100, 3662)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m3\u001b[0m\u001b[97m(-100, 18)\u001b[0m \u001b[31m >>\u001b[0m\u001b[97m(-100, 3662)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m4\u001b[0m\u001b[97m(-100, 19)\u001b[0m \u001b[31m >>\u001b[0m\u001b[97m(-100, 3662)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m;\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 401)\u001b[0m \u001b[31m\tlong\u001b[0m\u001b[97m(-100, 17972)\u001b[0m \u001b[31m long\u001b[0m\u001b[97m(-100, 1317)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m sum\u001b[0m\u001b[97m(-100, 2694)\u001b[0m \u001b[31m =\u001b[0m\u001b[97m(-100, 284)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m +\u001b[0m\u001b[97m(-100, 489)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m2\u001b[0m\u001b[97m(-100, 17)\u001b[0m \u001b[31m +\u001b[0m\u001b[97m(-100, 489)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m3\u001b[0m\u001b[97m(-100, 18)\u001b[0m \u001b[31m +\u001b[0m\u001b[97m(-100, 489)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m4\u001b[0m\u001b[97m(-100, 19)\u001b[0m \u001b[31m +\u001b[0m\u001b[97m(-100, 489)\u001b[0m \u001b[31m c\u001b[0m\u001b[97m(-100, 272)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m;\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 401)\u001b[0m \u001b[31m\tif\u001b[0m\u001b[97m(-100, 748)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31msum\u001b[0m\u001b[97m(-100, 1264)\u001b[0m \u001b[31m %\u001b[0m\u001b[97m(-100, 1034)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m ==\u001b[0m\u001b[97m(-100, 624)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m0\u001b[0m\u001b[97m(-100, 15)\u001b[0m \u001b[31m &&\u001b[0m\u001b[97m(-100, 1024)\u001b[0m \u001b[31m sum\u001b[0m\u001b[97m(-100, 2694)\u001b[0m \u001b[31m!=\u001b[0m\u001b[97m(-100, 976)\u001b[0m \u001b[31m0\u001b[0m\u001b[97m(-100, 15)\u001b[0m \u001b[31m )\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 5235)\u001b[0m \u001b[31m\t\u001b[0m\u001b[97m(-100, 197)\u001b[0m \u001b[31m\tcout\u001b[0m\u001b[97m(-100, 7856)\u001b[0m \u001b[31m <<\u001b[0m\u001b[97m(-100, 1134)\u001b[0m \u001b[31m sum\u001b[0m\u001b[97m(-100, 2694)\u001b[0m \u001b[31m /\u001b[0m\u001b[97m(-100, 611)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m;\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 401)\u001b[0m \u001b[31m\telse\u001b[0m\u001b[97m(-100, 2525)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31m\t\u001b[0m\u001b[97m(-100, 197)\u001b[0m \u001b[31m\tcout\u001b[0m\u001b[97m(-100, 7856)\u001b[0m \u001b[31m <<\u001b[0m\u001b[97m(-100, 1134)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m;\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 401)\u001b[0m \u001b[31m\treturn\u001b[0m\u001b[97m(-100, 862)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m0\u001b[0m\u001b[97m(-100, 15)\u001b[0m \u001b[31m;\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 401)\u001b[0m \u001b[31m}\n",
            "\u001b[0m\u001b[97m(-100, 534)\u001b[0m \u001b[31m```\u001b[0m\u001b[97m(-100, 74694)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[32m**\u001b[0m\u001b[97m(334, 334)\u001b[0m \u001b[32mExplanation\u001b[0m\u001b[97m(70869, 70869)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m**\n",
            "\n",
            "\u001b[0m\u001b[97m(57277, 57277)\u001b[0m \u001b[32mThis\u001b[0m\u001b[97m(2028, 2028)\u001b[0m \u001b[32m C\u001b[0m\u001b[97m(356, 356)\u001b[0m \u001b[32m++\u001b[0m\u001b[97m(1044, 1044)\u001b[0m \u001b[32m code\u001b[0m\u001b[97m(2082, 2082)\u001b[0m \u001b[32m takes\u001b[0m\u001b[97m(5097, 5097)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m integers\u001b[0m\u001b[97m(26864, 26864)\u001b[0m \u001b[32m as\u001b[0m\u001b[97m(439, 439)\u001b[0m \u001b[32m input\u001b[0m\u001b[97m(1988, 1988)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m `\u001b[0m\u001b[97m(1595, 1595)\u001b[0m \u001b[32mc\u001b[0m\u001b[97m(66, 66)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m`,\u001b[0m\u001b[97m(7964, 7964)\u001b[0m \u001b[32m `\u001b[0m\u001b[97m(1595, 1595)\u001b[0m \u001b[32mc\u001b[0m\u001b[97m(66, 66)\u001b[0m \u001b[32m2\u001b[0m\u001b[97m(17, 17)\u001b[0m \u001b[32m`,\u001b[0m\u001b[97m(7964, 7964)\u001b[0m \u001b[32m `\u001b[0m\u001b[97m(1595, 1595)\u001b[0m \u001b[32mc\u001b[0m\u001b[97m(66, 66)\u001b[0m \u001b[32m3\u001b[0m\u001b[97m(18, 18)\u001b[0m \u001b[32m`,\u001b[0m\u001b[97m(7964, 7964)\u001b[0m \u001b[32m `\u001b[0m\u001b[97m(1595, 1595)\u001b[0m \u001b[32mc\u001b[0m\u001b[97m(66, 66)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m`,\u001b[0m\u001b[97m(7964, 7964)\u001b[0m \u001b[32m and\u001b[0m\u001b[97m(323, 323)\u001b[0m \u001b[32m `\u001b[0m\u001b[97m(1595, 1595)\u001b[0m \u001b[32mc\u001b[0m\u001b[97m(66, 66)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m`.\u001b[0m\u001b[97m(29687, 29687)\u001b[0m \u001b[32m It\u001b[0m\u001b[97m(1102, 1102)\u001b[0m \u001b[32m computes\u001b[0m\u001b[97m(58303, 58303)\u001b[0m \u001b[32m their\u001b[0m\u001b[97m(872, 872)\u001b[0m \u001b[32m sum\u001b[0m\u001b[97m(2694, 2694)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m If\u001b[0m\u001b[97m(1442, 1442)\u001b[0m \u001b[32m their\u001b[0m\u001b[97m(872, 872)\u001b[0m \u001b[32m sum\u001b[0m\u001b[97m(2694, 2694)\u001b[0m \u001b[32m is\u001b[0m\u001b[97m(374, 374)\u001b[0m \u001b[32m not\u001b[0m\u001b[97m(539, 539)\u001b[0m \u001b[32m zero\u001b[0m\u001b[97m(7315, 7315)\u001b[0m \u001b[32m and\u001b[0m\u001b[97m(323, 323)\u001b[0m \u001b[32m divisible\u001b[0m\u001b[97m(76016, 76016)\u001b[0m \u001b[32m by\u001b[0m\u001b[97m(555, 555)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m it\u001b[0m\u001b[97m(433, 433)\u001b[0m \u001b[32m outputs\u001b[0m\u001b[97m(16674, 16674)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m result\u001b[0m\u001b[97m(1121, 1121)\u001b[0m \u001b[32m of\u001b[0m\u001b[97m(315, 315)\u001b[0m \u001b[32m `\u001b[0m\u001b[97m(1595, 1595)\u001b[0m \u001b[32msum\u001b[0m\u001b[97m(1264, 1264)\u001b[0m \u001b[32m //\u001b[0m\u001b[97m(443, 443)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m`.\u001b[0m\u001b[97m(29687, 29687)\u001b[0m \u001b[32m Otherwise\u001b[0m\u001b[97m(18715, 18715)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m it\u001b[0m\u001b[97m(433, 433)\u001b[0m \u001b[32m outputs\u001b[0m\u001b[97m(16674, 16674)\u001b[0m \u001b[32m `-\u001b[0m\u001b[97m(94897, 94897)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m`.\n",
            "\n",
            "\u001b[0m\u001b[97m(63438, 63438)\u001b[0m \u001b[32mThe\u001b[0m\u001b[97m(791, 791)\u001b[0m \u001b[32m logic\u001b[0m\u001b[97m(12496, 12496)\u001b[0m \u001b[32m is\u001b[0m\u001b[97m(374, 374)\u001b[0m \u001b[32m:\n",
            "\u001b[0m\u001b[97m(512, 512)\u001b[0m \u001b[32m-\u001b[0m\u001b[97m(12, 12)\u001b[0m \u001b[32m Read\u001b[0m\u001b[97m(4557, 4557)\u001b[0m \u001b[32m five\u001b[0m\u001b[97m(4330, 4330)\u001b[0m \u001b[32m integers\u001b[0m\u001b[97m(26864, 26864)\u001b[0m \u001b[32m.\n",
            "\u001b[0m\u001b[97m(627, 627)\u001b[0m \u001b[32m-\u001b[0m\u001b[97m(12, 12)\u001b[0m \u001b[32m Compute\u001b[0m\u001b[97m(23426, 23426)\u001b[0m \u001b[32m their\u001b[0m\u001b[97m(872, 872)\u001b[0m \u001b[32m sum\u001b[0m\u001b[97m(2694, 2694)\u001b[0m \u001b[32m.\n",
            "\u001b[0m\u001b[97m(627, 627)\u001b[0m \u001b[32m-\u001b[0m\u001b[97m(12, 12)\u001b[0m \u001b[32m If\u001b[0m\u001b[97m(1442, 1442)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m sum\u001b[0m\u001b[97m(2694, 2694)\u001b[0m \u001b[32m is\u001b[0m\u001b[97m(374, 374)\u001b[0m \u001b[32m not\u001b[0m\u001b[97m(539, 539)\u001b[0m \u001b[32m zero\u001b[0m\u001b[97m(7315, 7315)\u001b[0m \u001b[32m and\u001b[0m\u001b[97m(323, 323)\u001b[0m \u001b[32m divisible\u001b[0m\u001b[97m(76016, 76016)\u001b[0m \u001b[32m by\u001b[0m\u001b[97m(555, 555)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m print\u001b[0m\u001b[97m(1194, 1194)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m sum\u001b[0m\u001b[97m(2694, 2694)\u001b[0m \u001b[32m divided\u001b[0m\u001b[97m(18255, 18255)\u001b[0m \u001b[32m by\u001b[0m\u001b[97m(555, 555)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m.\n",
            "\u001b[0m\u001b[97m(627, 627)\u001b[0m \u001b[32m-\u001b[0m\u001b[97m(12, 12)\u001b[0m \u001b[32m Else\u001b[0m\u001b[97m(19334, 19334)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m print\u001b[0m\u001b[97m(1194, 1194)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m.\n",
            "\n",
            "\u001b[0m\u001b[97m(382, 382)\u001b[0m \u001b[32mBelow\u001b[0m\u001b[97m(39314, 39314)\u001b[0m \u001b[32m is\u001b[0m\u001b[97m(374, 374)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m equivalent\u001b[0m\u001b[97m(13890, 13890)\u001b[0m \u001b[32m Python\u001b[0m\u001b[97m(13325, 13325)\u001b[0m \u001b[32m code\u001b[0m\u001b[97m(2082, 2082)\u001b[0m \u001b[32m.\n",
            "\n",
            "\u001b[0m\u001b[97m(382, 382)\u001b[0m \u001b[32m```\u001b[0m\u001b[97m(74694, 74694)\u001b[0m \u001b[32mpython\u001b[0m\u001b[97m(12958, 12958)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32mdef\u001b[0m\u001b[97m(755, 755)\u001b[0m \u001b[32m solve\u001b[0m\u001b[97m(11886, 11886)\u001b[0m \u001b[32m():\n",
            "\u001b[0m\u001b[97m(4019, 4019)\u001b[0m \u001b[32m   \u001b[0m\u001b[97m(262, 262)\u001b[0m \u001b[32m c\u001b[0m\u001b[97m(272, 272)\u001b[0m \u001b[32m =\u001b[0m\u001b[97m(284, 284)\u001b[0m \u001b[32m list\u001b[0m\u001b[97m(1160, 1160)\u001b[0m \u001b[32m(map\u001b[0m\u001b[97m(9325, 9325)\u001b[0m \u001b[32m(int\u001b[0m\u001b[97m(1577, 1577)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m input\u001b[0m\u001b[97m(1988, 1988)\u001b[0m \u001b[32m().\u001b[0m\u001b[97m(1020, 1020)\u001b[0m \u001b[32msplit\u001b[0m\u001b[97m(7105, 7105)\u001b[0m \u001b[32m()))\n",
            "\u001b[0m\u001b[97m(12419, 12419)\u001b[0m \u001b[32m   \u001b[0m\u001b[97m(262, 262)\u001b[0m \u001b[32m total\u001b[0m\u001b[97m(2860, 2860)\u001b[0m \u001b[32m =\u001b[0m\u001b[97m(284, 284)\u001b[0m \u001b[32m sum\u001b[0m\u001b[97m(2694, 2694)\u001b[0m \u001b[32m(c\u001b[0m\u001b[97m(1361, 1361)\u001b[0m \u001b[32m)\n",
            "\u001b[0m\u001b[97m(340, 340)\u001b[0m \u001b[32m   \u001b[0m\u001b[97m(262, 262)\u001b[0m \u001b[32m if\u001b[0m\u001b[97m(422, 422)\u001b[0m \u001b[32m total\u001b[0m\u001b[97m(2860, 2860)\u001b[0m \u001b[32m %\u001b[0m\u001b[97m(1034, 1034)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m ==\u001b[0m\u001b[97m(624, 624)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m0\u001b[0m\u001b[97m(15, 15)\u001b[0m \u001b[32m and\u001b[0m\u001b[97m(323, 323)\u001b[0m \u001b[32m total\u001b[0m\u001b[97m(2860, 2860)\u001b[0m \u001b[32m!=\u001b[0m\u001b[97m(976, 976)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m0\u001b[0m\u001b[97m(15, 15)\u001b[0m \u001b[32m:\n",
            "\u001b[0m\u001b[97m(512, 512)\u001b[0m \u001b[32m       \u001b[0m\u001b[97m(286, 286)\u001b[0m \u001b[32m print\u001b[0m\u001b[97m(1194, 1194)\u001b[0m \u001b[32m(total\u001b[0m\u001b[97m(23689, 23689)\u001b[0m \u001b[32m //\u001b[0m\u001b[97m(443, 443)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m)\n",
            "\u001b[0m\u001b[97m(340, 340)\u001b[0m \u001b[32m   \u001b[0m\u001b[97m(262, 262)\u001b[0m \u001b[32m else\u001b[0m\u001b[97m(775, 775)\u001b[0m \u001b[32m:\n",
            "\u001b[0m\u001b[97m(512, 512)\u001b[0m \u001b[32m       \u001b[0m\u001b[97m(286, 286)\u001b[0m \u001b[32m print\u001b[0m\u001b[97m(1194, 1194)\u001b[0m \u001b[32m(-\u001b[0m\u001b[97m(4172, 4172)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m)\n",
            "\n",
            "\u001b[0m\u001b[97m(696, 696)\u001b[0m \u001b[32mif\u001b[0m\u001b[97m(333, 333)\u001b[0m \u001b[32m __\u001b[0m\u001b[97m(1328, 1328)\u001b[0m \u001b[32mname\u001b[0m\u001b[97m(609, 609)\u001b[0m \u001b[32m__\u001b[0m\u001b[97m(565, 565)\u001b[0m \u001b[32m ==\u001b[0m\u001b[97m(624, 624)\u001b[0m \u001b[32m \"__\u001b[0m\u001b[97m(13568, 13568)\u001b[0m \u001b[32mmain\u001b[0m\u001b[97m(3902, 3902)\u001b[0m \u001b[32m__\":\n",
            "\u001b[0m\u001b[97m(21762, 21762)\u001b[0m \u001b[32m   \u001b[0m\u001b[97m(262, 262)\u001b[0m \u001b[32m solve\u001b[0m\u001b[97m(11886, 11886)\u001b[0m \u001b[32m()\n",
            "\u001b[0m\u001b[97m(746, 746)\u001b[0m \u001b[32m```\u001b[0m\u001b[97m(74694, 74694)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m\u001b[39m\n",
            "[2025-11-19 02:36:29,678] [INFO] [axolotl.utils.tokenization.check_example_labels:45] [PID:11269] [RANK:0] \n",
            "\n",
            "\n",
            "\u001b[39m\n",
            "[2025-11-19 02:36:29,678] [INFO] [axolotl.utils.tokenization.check_example_labels:48] [PID:11269] [RANK:0] Total input len: 480\u001b[39m\n",
            "[2025-11-19 02:36:29,678] [INFO] [axolotl.utils.tokenization.check_example_labels:49] [PID:11269] [RANK:0] Count of labels: 186\u001b[39m\n",
            "[2025-11-19 02:36:29,678] [INFO] [axolotl.common.datasets.load_datasets:90] [PID:11269] [RANK:0] printing prompters...\u001b[39m\n",
            "[2025-11-19 02:36:29,678] [INFO] [axolotl.common.datasets.load_datasets:92] [PID:11269] [RANK:0] Pre-tokenized or custom dataset types are unsupported for logging\u001b[39m\n",
            "We detected that you are using `from_pretrained` with a meta device context manager or `torch.set_default_device('meta')`\n",
            "This is an anti-pattern and will raise an Error in version v4.53\n",
            "If you want to initialize a model on the meta device, use the context manager or global device with `from_config`, or `ModelClass(config)`\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 55.3MB/s]\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [02:44<00:00, 30.1MB/s]\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:52<00:00, 28.0MB/s]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  2.57it/s]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 1.31MB/s]\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "ds = load_from_disk(\"./last_run_prepared/0d8b032105993cd50c291ef141081e49\")\n",
        "print(ds[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2voGQFq2U6q",
        "outputId": "6799e6f0-697f-4ec3-9851-7753d1eaf6b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 777, 4723, 220, 2366, 20, 271, 2675, 527, 459, 8479, 430, 27983, 13325, 2082, 3196, 389, 279, 3984, 356, 1044, 2592, 2082, 627, 5451, 10552, 279, 2082, 11, 1243, 7068, 279, 13890, 13325, 2082, 627, 7927, 2082, 1288, 1373, 505, 5410, 1988, 323, 3350, 311, 5410, 2612, 627, 2746, 1070, 374, 2587, 12496, 304, 279, 356, 1044, 2082, 311, 1373, 1988, 477, 3350, 2612, 505, 3626, 304, 2254, 11, 40071, 433, 627, 2028, 2082, 374, 459, 8292, 315, 264, 15022, 15840, 3575, 11, 3234, 539, 1304, 904, 32946, 922, 279, 1988, 3645, 6062, 433, 690, 3775, 627, 19648, 279, 8066, 13325, 2082, 4871, 264, 2082, 2565, 449, 24657, 1203, 36178, 627, 13617, 512, 74694, 12958, 198, 475, 5826, 271, 755, 11886, 4019, 262, 1522, 271, 333, 1328, 609, 565, 624, 13568, 3902, 21762, 262, 11886, 746, 74694, 128009, 128006, 882, 128007, 271, 14196, 4077, 1085, 366, 9862, 397, 1085, 366, 3295, 397, 1085, 366, 2235, 397, 1085, 366, 751, 397, 1085, 366, 20266, 397, 1085, 366, 39466, 397, 1085, 366, 31616, 397, 1085, 366, 34825, 397, 1085, 366, 7848, 397, 1085, 366, 38312, 397, 1085, 366, 40006, 397, 1085, 366, 928, 870, 397, 1085, 366, 4687, 397, 985, 4573, 1487, 401, 396, 1925, 368, 341, 262, 528, 308, 401, 262, 8628, 3662, 308, 401, 262, 5142, 1134, 308, 280, 262, 369, 320, 396, 602, 284, 220, 16, 26, 602, 366, 308, 26, 602, 2516, 5142, 1134, 330, 330, 1134, 602, 280, 262, 5142, 1134, 5342, 401, 262, 471, 220, 15, 280, 457, 74694, 128009, 128006, 78191, 128007, 271, 334, 70869, 25, 57277, 791, 2082, 16181, 459, 7698, 1595, 77, 63, 505, 5410, 1988, 13, 2355, 2181, 24370, 279, 1396, 1595, 77, 63, 1176, 11, 1243, 24370, 279, 5219, 505, 220, 16, 709, 311, 1595, 77, 12, 16, 63, 320, 99461, 705, 682, 389, 279, 1890, 1584, 11, 19180, 555, 12908, 382, 2520, 3187, 11, 369, 1988, 1595, 19, 7964, 2612, 374, 512, 14196, 4077, 19, 220, 16, 220, 17, 220, 18, 198, 14196, 19884, 334, 31380, 2373, 25, 57277, 74694, 12958, 198, 755, 1925, 4019, 262, 308, 284, 528, 5498, 2455, 262, 1194, 1471, 11, 842, 52527, 262, 369, 602, 304, 2134, 7, 16, 11, 308, 997, 286, 1194, 446, 21532, 2293, 1998, 705, 842, 52527, 262, 1194, 2892, 333, 1328, 609, 565, 624, 13568, 3902, 21762, 262, 1925, 746, 74694, 128009], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 334, 70869, 25, 57277, 791, 2082, 16181, 459, 7698, 1595, 77, 63, 505, 5410, 1988, 13, 2355, 2181, 24370, 279, 1396, 1595, 77, 63, 1176, 11, 1243, 24370, 279, 5219, 505, 220, 16, 709, 311, 1595, 77, 12, 16, 63, 320, 99461, 705, 682, 389, 279, 1890, 1584, 11, 19180, 555, 12908, 382, 2520, 3187, 11, 369, 1988, 1595, 19, 7964, 2612, 374, 512, 14196, 4077, 19, 220, 16, 220, 17, 220, 18, 198, 14196, 19884, 334, 31380, 2373, 25, 57277, 74694, 12958, 198, 755, 1925, 4019, 262, 308, 284, 528, 5498, 2455, 262, 1194, 1471, 11, 842, 52527, 262, 369, 602, 304, 2134, 7, 16, 11, 308, 997, 286, 1194, 446, 21532, 2293, 1998, 705, 842, 52527, 262, 1194, 2892, 333, 1328, 609, 565, 624, 13568, 3902, 21762, 262, 1925, 746, 74694, 128009], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "decoded = tok.decode(ds[0][\"input_ids\"])\n",
        "print(decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J-iSfeRA8UO",
        "outputId": "c5194f74-8099-4d59-bfa3-c1e1321f1ef2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 19 Nov 2025\n",
            "\n",
            "You are an agent that generates Python code based on the provided C++ source code.\n",
            "First explain the code, then generate the equivalent Python code.\n",
            "Your code should read from standard input and write to standard output.\n",
            "If there is custom logic in the C++ code to read input or write output from files in local, Ignore it.\n",
            "This code is an implementation of a competitive programming problem, Do not make any assumptions about the input format otherwise it will fail.\n",
            "Put the generated Python code inside a code block with triple backticks.\n",
            "Example:\n",
            "```python\n",
            "import sys\n",
            "\n",
            "def solve():\n",
            "    pass\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    solve()\n",
            "```<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "```\n",
            "#include <iostream>\n",
            "#include <vector>\n",
            "#include <map>\n",
            "#include <set>\n",
            "#include <algorithm>\n",
            "#include <sstream>\n",
            "#include <fstream>\n",
            "#include <cmath>\n",
            "#include <stack>\n",
            "#include <cstdio>\n",
            "#include <cstring>\n",
            "#include <string.h>\n",
            "#include <queue>\n",
            "using namespace std;\n",
            "\n",
            "int main() {\n",
            "    int n;\n",
            "\n",
            "    cin >> n;\n",
            "\n",
            "    cout << n;\n",
            "    for (int i = 1; i < n; i++) cout << \" \" << i;\n",
            "    cout << endl;\n",
            "\n",
            "    return 0;\n",
            " }\n",
            "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The code reads an integer `n` from standard input.  \n",
            "It prints the number `n` first, then prints the numbers from 1 up to `n-1` (inclusive), all on the same line, separated by spaces.\n",
            "\n",
            "For example, for input `4`, output is:\n",
            "```\n",
            "4 1 2 3\n",
            "```\n",
            "\n",
            "**Python version:**\n",
            "\n",
            "```python\n",
            "def main():\n",
            "    n = int(input())\n",
            "    print(n, end='')\n",
            "    for i in range(1, n):\n",
            "        print(\" {}\".format(i), end='')\n",
            "    print()\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && python -m axolotl.cli.train config/llama-3.2-3b-lora.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGByaznf2YqP",
        "outputId": "33ce5f27-1360-41f0-87a9-f11576a6e56b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-19 02:49:47.836177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763520587.868844   14831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763520587.878838   14831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763520587.903639   14831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763520587.903701   14831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763520587.903711   14831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763520587.903718   14831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-19 02:49:47.912037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-11-19 02:50:01,245] [INFO] [axolotl.utils.schemas.config.check_bf16:1003] [PID:14831] [RANK:0] bf16 support detected, but not enabled for this configuration.\u001b[39m\n",
            "[2025-11-19 02:50:01,425] [INFO] [axolotl.cli.config.load_cfg:245] [PID:14831] [RANK:0] config:\n",
            "{\n",
            "  \"activation_offloading\": false,\n",
            "  \"adapter\": \"lora\",\n",
            "  \"axolotl_config_path\": \"config/llama-3.2-3b-lora.yml\",\n",
            "  \"base_model\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
            "  \"base_model_config\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
            "  \"batch_size\": 8,\n",
            "  \"bf16\": false,\n",
            "  \"capabilities\": {\n",
            "    \"bf16\": true,\n",
            "    \"compute_capability\": \"sm_75\",\n",
            "    \"fp8\": false,\n",
            "    \"n_gpu\": 1,\n",
            "    \"n_node\": 1\n",
            "  },\n",
            "  \"context_parallel_size\": 1,\n",
            "  \"dataloader_num_workers\": 1,\n",
            "  \"dataloader_pin_memory\": true,\n",
            "  \"dataloader_prefetch_factor\": 256,\n",
            "  \"dataset_processes\": 2,\n",
            "  \"datasets\": [\n",
            "    {\n",
            "      \"chat_template\": \"tokenizer_default\",\n",
            "      \"message_property_mappings\": {\n",
            "        \"content\": \"content\",\n",
            "        \"role\": \"role\"\n",
            "      },\n",
            "      \"path\": \"./data/train_openai_response_transformed.jsonl\",\n",
            "      \"trust_remote_code\": false,\n",
            "      \"type\": \"chat_template\"\n",
            "    }\n",
            "  ],\n",
            "  \"ddp\": false,\n",
            "  \"device\": \"cuda:0\",\n",
            "  \"device_map\": \"auto\",\n",
            "  \"dion_rank_fraction\": 1.0,\n",
            "  \"dion_rank_multiple_of\": 1,\n",
            "  \"env_capabilities\": {\n",
            "    \"torch_version\": \"2.6.0\"\n",
            "  },\n",
            "  \"eval_batch_size\": 2,\n",
            "  \"eval_causal_lm_metrics\": [\n",
            "    \"sacrebleu\",\n",
            "    \"comet\",\n",
            "    \"ter\",\n",
            "    \"chrf\"\n",
            "  ],\n",
            "  \"eval_max_new_tokens\": 128,\n",
            "  \"eval_steps\": 100,\n",
            "  \"eval_table_size\": 0,\n",
            "  \"fp16\": true,\n",
            "  \"gradient_accumulation_steps\": 4,\n",
            "  \"gradient_checkpointing\": true,\n",
            "  \"gradient_checkpointing_kwargs\": {\n",
            "    \"use_reentrant\": true\n",
            "  },\n",
            "  \"is_falcon_derived_model\": false,\n",
            "  \"is_llama_derived_model\": true,\n",
            "  \"is_mistral_derived_model\": false,\n",
            "  \"learning_rate\": 0.0003,\n",
            "  \"lisa_layers_attribute\": \"model.layers\",\n",
            "  \"load_best_model_at_end\": false,\n",
            "  \"load_in_4bit\": false,\n",
            "  \"load_in_8bit\": true,\n",
            "  \"local_rank\": 0,\n",
            "  \"logging_steps\": 10,\n",
            "  \"lora_alpha\": 16,\n",
            "  \"lora_dropout\": 0.05,\n",
            "  \"lora_r\": 8,\n",
            "  \"lora_target_modules\": [\n",
            "    \"q_proj\",\n",
            "    \"k_proj\",\n",
            "    \"v_proj\",\n",
            "    \"o_proj\"\n",
            "  ],\n",
            "  \"loraplus_lr_embedding\": 1e-06,\n",
            "  \"lr_scheduler\": \"cosine\",\n",
            "  \"max_prompt_len\": 512,\n",
            "  \"mean_resizing_embeddings\": false,\n",
            "  \"micro_batch_size\": 2,\n",
            "  \"model_config_type\": \"llama\",\n",
            "  \"num_epochs\": 3.0,\n",
            "  \"optimizer\": \"adamw_torch_fused\",\n",
            "  \"output_dir\": \"./outputs\",\n",
            "  \"pretrain_multipack_attn\": true,\n",
            "  \"pretrain_multipack_buffer_size\": 10000,\n",
            "  \"profiler_steps_start\": 0,\n",
            "  \"qlora_sharded_model_loading\": false,\n",
            "  \"ray_num_workers\": 1,\n",
            "  \"resources_per_worker\": {\n",
            "    \"GPU\": 1\n",
            "  },\n",
            "  \"sample_packing_bin_size\": 200,\n",
            "  \"sample_packing_group_size\": 100000,\n",
            "  \"save_only_model\": false,\n",
            "  \"save_safetensors\": true,\n",
            "  \"save_steps\": 100,\n",
            "  \"seed\": 42,\n",
            "  \"sequence_len\": 512,\n",
            "  \"shuffle_before_merging_datasets\": false,\n",
            "  \"shuffle_merged_datasets\": true,\n",
            "  \"skip_prepare_dataset\": false,\n",
            "  \"strict\": false,\n",
            "  \"tensor_parallel_size\": 1,\n",
            "  \"tiled_mlp_use_original_mlp\": true,\n",
            "  \"tokenizer_config\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
            "  \"tokenizer_type\": \"LlamaTokenizerFast\",\n",
            "  \"torch_dtype\": \"torch.float16\",\n",
            "  \"train_on_inputs\": false,\n",
            "  \"trl\": {\n",
            "    \"log_completions\": false,\n",
            "    \"mask_truncated_completions\": false,\n",
            "    \"ref_model_mixup_alpha\": 0.9,\n",
            "    \"ref_model_sync_steps\": 64,\n",
            "    \"scale_rewards\": true,\n",
            "    \"sync_ref_model\": false,\n",
            "    \"use_vllm\": false,\n",
            "    \"vllm_server_host\": \"0.0.0.0\",\n",
            "    \"vllm_server_port\": 8000\n",
            "  },\n",
            "  \"type_of_model\": \"llama\",\n",
            "  \"use_ray\": false,\n",
            "  \"val_set_size\": 0.1,\n",
            "  \"vllm\": {\n",
            "    \"device\": \"auto\",\n",
            "    \"dtype\": \"auto\",\n",
            "    \"gpu_memory_utilization\": 0.9,\n",
            "    \"host\": \"0.0.0.0\",\n",
            "    \"port\": 8000\n",
            "  },\n",
            "  \"warmup_steps\": 100,\n",
            "  \"weight_decay\": 0.0,\n",
            "  \"world_size\": 1\n",
            "}\u001b[39m\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
            "The class this function is called from is 'LlamaTokenizerFast'.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "[2025-11-19 02:50:02,624] [INFO] [axolotl.loaders.tokenizer.load_tokenizer:300] [PID:14831] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-11-19 02:50:02,624] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:478] [PID:14831] [RANK:0] Unable to find prepared dataset in last_run_prepared/0d8b032105993cd50c291ef141081e49\u001b[39m\n",
            "[2025-11-19 02:50:02,625] [INFO] [axolotl.utils.data.sft._load_raw_datasets:314] [PID:14831] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-11-19 02:50:02,625] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:316] [PID:14831] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
            "[2025-11-19 02:50:02,950] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:14831] [RANK:0] Loading dataset: ./data/train_openai_response_transformed.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-11-19 02:50:02,956] [INFO] [axolotl.prompt_strategies.chat_template.__call__:957] [PID:14831] [RANK:0] Using chat template:\n",
            "---\n",
            "{{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- if strftime_now is defined %}\n",
            "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
            "    {%- else %}\n",
            "        {%- set date_string = \"26 Jul 2024\" %}\n",
            "    {%- endif %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "        {{- '\"parameters\": ' }}\n",
            "        {{- tool_call.arguments | tojson }}\n",
            "        {{- \"}\" }}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 1400/1400 [00:15<00:00, 89.19 examples/s] \n",
            "[2025-11-19 02:50:18,908] [INFO] [axolotl.utils.data.utils.handle_long_seq_in_dataset:209] [PID:14831] [RANK:0] min_input_len: 328\u001b[39m\n",
            "[2025-11-19 02:50:18,909] [INFO] [axolotl.utils.data.utils.handle_long_seq_in_dataset:211] [PID:14831] [RANK:0] max_input_len: 10300\u001b[39m\n",
            "Dropping Long Sequences (>512) (num_proc=2): 100% 1400/1400 [00:01<00:00, 1230.75 examples/s]\n",
            "\u001b[33m[2025-11-19 02:50:20,055] [WARNING] [axolotl.utils.data.utils.handle_long_seq_in_dataset:251] [PID:14831] [RANK:0] Dropped 1346 samples from dataset\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 54/54 [00:00<00:00, 9487.79 examples/s] \n",
            "[2025-11-19 02:50:20,114] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:127] [PID:14831] [RANK:0] Maximum number of steps set at 18\u001b[39m\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
            "The class this function is called from is 'LlamaTokenizerFast'.\n",
            "[2025-11-19 02:50:20,919] [INFO] [axolotl.loaders.tokenizer.load_tokenizer:300] [PID:14831] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-11-19 02:50:21,037] [INFO] [axolotl.monkeypatch.transformers.trainer_loss_calc.patch_evaluation_loop:110] [PID:14831] [RANK:0] Patched Trainer.evaluation_loop with nanmean loss calculation\u001b[39m\n",
            "[2025-11-19 02:50:21,038] [INFO] [axolotl.monkeypatch.transformers.trainer_loss_calc.patch_maybe_log_save_evaluate:164] [PID:14831] [RANK:0] Patched Trainer._maybe_log_save_evaluate with nanmean loss calculation\u001b[39m\n",
            "Loading checkpoint shards: 100% 2/2 [00:33<00:00, 16.54s/it]\n",
            "[2025-11-19 02:50:54,672] [INFO] [axolotl.loaders.model._prepare_model_for_quantization:874] [PID:14831] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-11-19 02:50:54,674] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:345] [PID:14831] [RANK:0] Converting modules to torch.float16\u001b[39m\n",
            "trainable params: 4,587,520 || all params: 3,217,340,416 || trainable%: 0.1426\n",
            "[2025-11-19 02:51:19,325] [INFO] [axolotl.train.save_initial_configs:412] [PID:14831] [RANK:0] Pre-saving adapter config to ./outputs...\u001b[39m\n",
            "[2025-11-19 02:51:19,326] [INFO] [axolotl.train.save_initial_configs:416] [PID:14831] [RANK:0] Pre-saving tokenizer to ./outputs...\u001b[39m\n",
            "[2025-11-19 02:51:19,550] [INFO] [axolotl.train.save_initial_configs:419] [PID:14831] [RANK:0] Pre-saving model config to ./outputs...\u001b[39m\n",
            "[2025-11-19 02:51:19,555] [INFO] [axolotl.train.execute_training:203] [PID:14831] [RANK:0] Starting trainer...\u001b[39m\n",
            "  0% 0/18 [00:00<?, ?it/s]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  5.79it/s]\u001b[A\n",
            "                          \n",
            "\u001b[A{'eval_loss': 0.9235135912895203, 'eval_runtime': 2.8118, 'eval_samples_per_second': 2.134, 'eval_steps_per_second': 1.067, 'memory/max_mem_active(gib)': 4.83, 'memory/max_mem_allocated(gib)': 4.83, 'memory/device_mem_reserved(gib)': 5.69, 'epoch': 0}\n",
            "  0% 0/18 [00:02<?, ?it/s]\n",
            "100% 3/3 [00:00<00:00,  3.24it/s]\u001b[A\n",
            "{'loss': 0.9145, 'grad_norm': 0.4988362789154053, 'learning_rate': 2.6999999999999996e-05, 'memory/max_mem_active(gib)': 5.09, 'memory/max_mem_allocated(gib)': 5.09, 'memory/device_mem_reserved(gib)': 5.69, 'epoch': 1.67}\n",
            "100% 18/18 [01:51<00:00,  6.15s/it][2025-11-19 02:53:11,209] [INFO] [axolotl.core.trainers.base._save:613] [PID:14831] [RANK:0] Saving model checkpoint to ./outputs/checkpoint-18\u001b[39m\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "[2025-11-19 02:54:09,421] [INFO] [axolotl.core.trainers.base._save:662] [PID:14831] [RANK:0] Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\u001b[39m\n",
            "{'train_runtime': 169.6962, 'train_samples_per_second': 0.849, 'train_steps_per_second': 0.106, 'train_loss': 0.8953777949015299, 'memory/max_mem_active(gib)': 5.09, 'memory/max_mem_allocated(gib)': 5.09, 'memory/device_mem_reserved(gib)': 5.69, 'epoch': 3.0}\n",
            "100% 18/18 [02:49<00:00,  9.43s/it]\n",
            "[2025-11-19 02:54:09,809] [INFO] [axolotl.train.save_trained_model:228] [PID:14831] [RANK:0] Training completed! Saving trained model to ./outputs.\u001b[39m\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "[2025-11-19 02:55:23,180] [INFO] [axolotl.train.save_trained_model:350] [PID:14831] [RANK:0] Model successfully saved to ./outputs\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvidia-smi\n",
        "\n",
        "import os\n",
        "output_files = os.listdir('./outputs')\n",
        "print(\"Output files:\", output_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBmOqNvp2exZ",
        "outputId": "0202284b-8504-4390-ae92-57eaae1aecab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 19 02:55:59 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Output files: ['tokenizer_config.json', 'checkpoint-18', 'adapter_config.json', 'README.md', 'adapter_model.safetensors', 'special_tokens_map.json', 'chat_template.jinja', 'tokenizer.json', 'config.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    \"./outputs\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Push to HuggingFace\n",
        "# merged_model.push_to_hub(\"your-username/llama-3.2-3b-finetuned\")\n",
        "# AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\").push_to_hub(\"your-username/llama-3.2-3b-finetuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "efe9ead585fb4f0c8e8280098b2a1872",
            "b5b391949a784bf39712109778f21212",
            "5c43665e4eeb4d31a40c488bd569e289",
            "4bcfa90f10784bc99a490fc5a610b09c",
            "be32b4da7dae44edaf395ee4cd9f2074",
            "991227b6c08648189b4f2c42401b7faa",
            "5b06c80b2f0b46ea806bf7aeee6c072d",
            "7411e8c3f1094036a522880a64a93dda",
            "316e129c2b4f49deaa86f58fbc633b18",
            "adff8e03e704431ea7087e7ffcc80ecd",
            "4b4e19371f814810a5549c56b208cf37"
          ]
        },
        "id": "npVRiA8N2iyu",
        "outputId": "e11a039f-f023-4313-f4b2-be288a6377d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe9ead585fb4f0c8e8280098b2a1872"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 752.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 278.12 MiB is free. Process 233674 has 14.47 GiB memory in use. Of the allocated memory 14.26 GiB is allocated by PyTorch, and 98.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-633659730.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model = PeftModel.from_pretrained(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"./outputs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m             )\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         load_result = model.load_adapter(\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mload_adapter\u001b[0;34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         adapters_weights = load_peft_weights(\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhf_hub_download_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py\u001b[0m in \u001b[0;36mload_peft_weights\u001b[0;34m(model_id, device, key_mapping, **hf_hub_download_kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0madapters_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0madapters_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0madapters_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 278.12 MiB is free. Process 233674 has 14.47 GiB memory in use. Of the allocated memory 14.26 GiB is allocated by PyTorch, and 98.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}